<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Preprocess breadtext | Taliban Project</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Preprocess breadtext | Taliban Project" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Preprocess breadtext | Taliban Project" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  

<meta name="author" content="Anders Havbro Hjulmand" />


<meta name="date" content="2021-11-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="scrape-bread-text-of-articles-1.html"/>
<link rel="next" href="overview-1.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.17/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/nouislider-7.0.10/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider-7.0.10/jquery.nouislider.min.js"></script>
<link href="libs/selectize-0.12.0/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize-0.12.0/selectize.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Taliban Project</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure"><i class="fa fa-check"></i>Structure</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#cross"><i class="fa fa-check"></i><b>0.1</b> Render book</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#preview-book"><i class="fa fa-check"></i><b>0.2</b> Preview book</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#this-is-where-you-add-packages"><i class="fa fa-check"></i><b>0.3</b> This is where you add packages</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#an-unnumbered-section"><i class="fa fa-check"></i>An unnumbered section</a></li>
</ul></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#chapters-and-sub-chapters"><i class="fa fa-check"></i><b>0.4</b> Chapters and sub-chapters</a></li>
<li class="chapter" data-level="0.5" data-path="index.html"><a href="index.html#captioned-figures-and-tables"><i class="fa fa-check"></i><b>0.5</b> Captioned figures and tables</a></li>
<li class="chapter" data-level="0.6" data-path="index.html"><a href="index.html#parts"><i class="fa fa-check"></i><b>0.6</b> Parts</a></li>
<li class="chapter" data-level="0.7" data-path="index.html"><a href="index.html#footnotes"><i class="fa fa-check"></i><b>0.7</b> Footnotes</a></li>
<li class="chapter" data-level="0.8" data-path="index.html"><a href="index.html#citations"><i class="fa fa-check"></i><b>0.8</b> Citations</a></li>
<li class="chapter" data-level="0.9" data-path="index.html"><a href="index.html#tips-and-tricks"><i class="fa fa-check"></i><b>0.9</b> Tips and Tricks</a></li>
</ul></li>
<li class="part"><span><b>I New York Times</b></span></li>
<li class="chapter" data-level="1" data-path="scraping-news-articles-with-new-york-times-api.html"><a href="scraping-news-articles-with-new-york-times-api.html"><i class="fa fa-check"></i><b>1</b> Scraping News Articles with New York Times API</a></li>
<li class="chapter" data-level="2" data-path="cleaning-the-data.html"><a href="cleaning-the-data.html"><i class="fa fa-check"></i><b>2</b> Cleaning The Data</a></li>
<li class="chapter" data-level="3" data-path="scrape-bread-text-of-articles.html"><a href="scrape-bread-text-of-articles.html"><i class="fa fa-check"></i><b>3</b> Scrape bread text of articles</a>
<ul>
<li class="chapter" data-level="3.1" data-path="scrape-bread-text-of-articles.html"><a href="scrape-bread-text-of-articles.html#scraping-in-python"><i class="fa fa-check"></i><b>3.1</b> Scraping in Python</a></li>
<li class="chapter" data-level="3.2" data-path="scrape-bread-text-of-articles.html"><a href="scrape-bread-text-of-articles.html#inspecting-the-bread-text"><i class="fa fa-check"></i><b>3.2</b> Inspecting the bread text</a></li>
</ul></li>
<li class="part"><span><b>II The Guardian</b></span></li>
<li class="chapter" data-level="4" data-path="scraping-articles-form-the-guardian.html"><a href="scraping-articles-form-the-guardian.html"><i class="fa fa-check"></i><b>4</b> Scraping articles form the Guardian</a></li>
<li class="chapter" data-level="5" data-path="cleaning-articles.html"><a href="cleaning-articles.html"><i class="fa fa-check"></i><b>5</b> Cleaning articles</a></li>
<li class="chapter" data-level="6" data-path="scrape-bread-text-of-articles-1.html"><a href="scrape-bread-text-of-articles-1.html"><i class="fa fa-check"></i><b>6</b> Scrape bread text of articles</a></li>
<li class="part"><span><b>III Preprocess breadtext in both datasets</b></span></li>
<li class="chapter" data-level="7" data-path="preprocess-breadtext.html"><a href="preprocess-breadtext.html"><i class="fa fa-check"></i><b>7</b> Preprocess breadtext</a></li>
<li class="part"><span><b>IV Named Entity recognition (NER)</b></span></li>
<li class="chapter" data-level="" data-path="overview-1.html"><a href="overview-1.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="overview-1.html"><a href="overview-1.html#structure-1"><i class="fa fa-check"></i>Structure</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="extracting-ners.html"><a href="extracting-ners.html"><i class="fa fa-check"></i><b>8</b> Extracting NER’s</a></li>
<li class="chapter" data-level="9" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html"><i class="fa fa-check"></i><b>9</b> GPE vizualisations</a>
<ul>
<li class="chapter" data-level="9.1" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#preparing-the-data"><i class="fa fa-check"></i><b>9.1</b> Preparing the data</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#renaming-countries"><i class="fa fa-check"></i><b>9.1.1</b> Renaming Countries</a></li>
<li class="chapter" data-level="9.1.2" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#every-country-gets-a-row-for-every-date"><i class="fa fa-check"></i><b>9.1.2</b> Every country gets a row for every date</a></li>
<li class="chapter" data-level="9.1.3" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#making-a-unique-dataset-for-plotly-and-shiny-respectively"><i class="fa fa-check"></i><b>9.1.3</b> Making a unique dataset for Plotly and Shiny respectively</a></li>
<li class="chapter" data-level="9.1.4" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#making-a-penalized-count"><i class="fa fa-check"></i><b>9.1.4</b> Making a penalized count</a></li>
<li class="chapter" data-level="9.1.5" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#setting-up-the-binsize"><i class="fa fa-check"></i><b>9.1.5</b> Setting up the binsize</a></li>
<li class="chapter" data-level="9.1.6" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#fixing-the-legend-scales-to-absolute-values."><i class="fa fa-check"></i><b>9.1.6</b> Fixing the legend scales to absolute values.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#interactive-maps-using-plotly"><i class="fa fa-check"></i><b>9.2</b> Interactive maps using Plotly</a></li>
<li class="chapter" data-level="9.3" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#shiny-app"><i class="fa fa-check"></i><b>9.3</b> Shiny App</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="vizualising-key-persons.html"><a href="vizualising-key-persons.html"><i class="fa fa-check"></i><b>10</b> Vizualising Key persons</a></li>
<li class="part"><span><b>V Sentiment Analysis</b></span></li>
<li class="chapter" data-level="" data-path="overview-2.html"><a href="overview-2.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="11" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html"><i class="fa fa-check"></i><b>11</b> Sentiment Analysis</a></li>
<li class="chapter" data-level="12" data-path="sentiment-vizualisations.html"><a href="sentiment-vizualisations.html"><i class="fa fa-check"></i><b>12</b> Sentiment Vizualisations</a></li>
<li class="part"><span><b>VI LDA Topic Modelling</b></span></li>
<li class="chapter" data-level="" data-path="overview-3.html"><a href="overview-3.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="13" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html"><i class="fa fa-check"></i><b>13</b> LDA Topic Modelling</a>
<ul>
<li class="chapter" data-level="13.1" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#bigrams-and-trigrams"><i class="fa fa-check"></i><b>13.1</b> Bigrams and Trigrams</a></li>
<li class="chapter" data-level="13.2" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#removing-frequently-occuring-words"><i class="fa fa-check"></i><b>13.2</b> Removing frequently occuring words</a></li>
<li class="chapter" data-level="13.3" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#creating-basic-lda-topic-model"><i class="fa fa-check"></i><b>13.3</b> Creating Basic LDA Topic Model</a></li>
<li class="chapter" data-level="13.4" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#selecting-the-number-of-topics"><i class="fa fa-check"></i><b>13.4</b> Selecting the number of topics</a></li>
<li class="chapter" data-level="13.5" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#creating-final-model"><i class="fa fa-check"></i><b>13.5</b> Creating final model</a></li>
<li class="chapter" data-level="13.6" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#assigning-one-topic-to-each-article"><i class="fa fa-check"></i><b>13.6</b> Assigning one topic to each article</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="topic-model-interpretation-and-vizualisation.html"><a href="topic-model-interpretation-and-vizualisation.html"><i class="fa fa-check"></i><b>14</b> Topic Model Interpretation and Vizualisation</a></li>
<li class="part"><span><b>VII All Results and Vizualisations</b></span></li>
<li class="chapter" data-level="15" data-path="all-results-and-vizualisation.html"><a href="all-results-and-vizualisation.html"><i class="fa fa-check"></i><b>15</b> All Results and Vizualisation</a></li>
<li class="part"><span><b>VIII Gender Dataset for further analysis</b></span></li>
<li class="chapter" data-level="16" data-path="gender-dataset-for-further-analysis.html"><a href="gender-dataset-for-further-analysis.html"><i class="fa fa-check"></i><b>16</b> Gender Dataset for further analysis</a>
<ul>
<li class="chapter" data-level="16.1" data-path="gender-dataset-for-further-analysis.html"><a href="gender-dataset-for-further-analysis.html#dataset-with-authors"><i class="fa fa-check"></i><b>16.1</b> Dataset with authors</a></li>
<li class="chapter" data-level="16.2" data-path="gender-dataset-for-further-analysis.html"><a href="gender-dataset-for-further-analysis.html#comparing-the-datasets"><i class="fa fa-check"></i><b>16.2</b> Comparing the datasets</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="adding-gender-information-to-nyt_aut.html"><a href="adding-gender-information-to-nyt_aut.html"><i class="fa fa-check"></i><b>17</b> Adding gender information to <code>NYT_aut</code></a></li>
<li class="part"><span><b>IX References</b></span></li>
<li class="chapter" data-level="18" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>18</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">See Github Repo</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Taliban Project</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="preprocess-breadtext" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> Preprocess breadtext</h1>
<p><em>Note: This chapter is written in Python. To see the original file go to the folder python/scripts</em>
<em>All the code in the chapter is run on both <code>df_NYT</code> and <code>df_guardian</code> but here i only show the processing <code>df_NYT</code>.</em></p>
<p>Now we are going to move into the domain of Natural Language Processing (NLP). This is a huge field with many applications and many methods/analysis. Moreover there are a ton of packages in both R and Python for doing NLP. I have chosen to use a package in python called <code>spacy</code>. This package is really powerful and has great documentation. See their webpage to get started: <a href="https://spacy.io/" class="uri">https://spacy.io/</a>.</p>
<p>So, going back to the project we have scraped the breadtext from all the articles. We need to preprocess that text before we can apply NLP-analysis. We also use <code>spacy</code> to preprocess the text because it has some useful functions. The preprocessing contains three major steps:</p>
<ol style="list-style-type: decimal">
<li>We remove punctuation and special characters.</li>
<li>We remove <em>stopwords</em>. Stopwords are those common/neutral words that do not add meaning to a text. These are words such as <em>allow</em> or <em>a</em>.</li>
<li>We <em>lemmatize</em> all the words. Lemmatization is the process of returning all words to their most basic form, the <em>lemma</em>. For example, the verb <em>to walk</em> may appear as <em>walk</em>, <em>walked</em> or <em>walking</em>. Lemmatization returns all these forms of walking to their base form <em>to walk</em>.</li>
</ol>
<p>All right, lets see some code. We run all the code below for both <code>df_NYT</code> and <code>df_guardian</code>, but I only show the code for <code>df_NYT</code>.
We start by loading packages and data.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="preprocess-breadtext.html#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb52-2"><a href="preprocess-breadtext.html#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb52-3"><a href="preprocess-breadtext.html#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb52-4"><a href="preprocess-breadtext.html#cb52-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-5"><a href="preprocess-breadtext.html#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="co">#importing the stopwords</span></span>
<span id="cb52-6"><a href="preprocess-breadtext.html#cb52-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> spacy.lang.en.stop_words <span class="im">import</span> STOP_WORDS</span>
<span id="cb52-7"><a href="preprocess-breadtext.html#cb52-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-8"><a href="preprocess-breadtext.html#cb52-8" aria-hidden="true" tabindex="-1"></a><span class="co">#loading the dataframes and combining them </span></span>
<span id="cb52-9"><a href="preprocess-breadtext.html#cb52-9" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> pd.read_csv(<span class="st">&quot;data/new_york_times/NYT_clean_1.csv&quot;</span>)</span>
<span id="cb52-10"><a href="preprocess-breadtext.html#cb52-10" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> pd.read_csv(<span class="st">&quot;data/new_york_times/NYT_clean_2.csv&quot;</span>)</span>
<span id="cb52-11"><a href="preprocess-breadtext.html#cb52-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-12"><a href="preprocess-breadtext.html#cb52-12" aria-hidden="true" tabindex="-1"></a><span class="co">#combining</span></span>
<span id="cb52-13"><a href="preprocess-breadtext.html#cb52-13" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.concat([df1, df2])</span></code></pre></div>
<p>Then we load what is called the english small pipeline from <code>spacy</code>. This is basicly a nlp-model with lots of cool functions that we are going to use. We also exclude certain components of the pipeline that we dont need to speed up processing.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="preprocess-breadtext.html#cb53-1" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> spacy.load(<span class="st">&quot;en_core_web_sm&quot;</span>, exclude<span class="op">=</span>[<span class="st">&quot;ner&quot;</span>, <span class="st">&quot;entity_linker&quot;</span>, <span class="st">&quot;entity_ruler&quot;</span>])</span></code></pre></div>
<p>Now we can define helper functions that performs the preprocessing steps described above. We first define a function that removes punctuation, special characters and stopwords. It takes ‘article’ as argument which is one breadtext from an article. It then converts that article to an <code>nlp-object</code> which is necesarry for the functions to work. It then looks through all the tokens (which is basically all the words) and filters out special characters, stopwords and extra spaces.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="preprocess-breadtext.html#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># function for Removing punctuation, stopwords and special chars from a sentence using spaCy </span></span>
<span id="cb54-2"><a href="preprocess-breadtext.html#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_special_chars_and_stopwords(article):</span>
<span id="cb54-3"><a href="preprocess-breadtext.html#cb54-3" aria-hidden="true" tabindex="-1"></a> article <span class="op">=</span> nlp(article)</span>
<span id="cb54-4"><a href="preprocess-breadtext.html#cb54-4" aria-hidden="true" tabindex="-1"></a> article <span class="op">=</span> <span class="st">&#39; &#39;</span>.join([token.text <span class="cf">for</span> token <span class="kw">in</span> article </span>
<span id="cb54-5"><a href="preprocess-breadtext.html#cb54-5" aria-hidden="true" tabindex="-1"></a> <span class="cf">if</span> token.is_punct <span class="op">!=</span> <span class="va">True</span> <span class="kw">and</span> </span>
<span id="cb54-6"><a href="preprocess-breadtext.html#cb54-6" aria-hidden="true" tabindex="-1"></a>     token.is_quote <span class="op">!=</span> <span class="va">True</span> <span class="kw">and</span> </span>
<span id="cb54-7"><a href="preprocess-breadtext.html#cb54-7" aria-hidden="true" tabindex="-1"></a>     token.is_bracket <span class="op">!=</span> <span class="va">True</span> <span class="kw">and</span> </span>
<span id="cb54-8"><a href="preprocess-breadtext.html#cb54-8" aria-hidden="true" tabindex="-1"></a>     token.is_currency <span class="op">!=</span> <span class="va">True</span> <span class="kw">and</span> </span>
<span id="cb54-9"><a href="preprocess-breadtext.html#cb54-9" aria-hidden="true" tabindex="-1"></a>     token.is_digit <span class="op">!=</span> <span class="va">True</span> <span class="kw">and</span></span>
<span id="cb54-10"><a href="preprocess-breadtext.html#cb54-10" aria-hidden="true" tabindex="-1"></a>     token.is_stop <span class="op">!=</span> <span class="va">True</span>])</span>
<span id="cb54-11"><a href="preprocess-breadtext.html#cb54-11" aria-hidden="true" tabindex="-1"></a> <span class="co">#removing extra spaces</span></span>
<span id="cb54-12"><a href="preprocess-breadtext.html#cb54-12" aria-hidden="true" tabindex="-1"></a> article <span class="op">=</span> <span class="st">&quot; &quot;</span>.join(article.split())</span>
<span id="cb54-13"><a href="preprocess-breadtext.html#cb54-13" aria-hidden="true" tabindex="-1"></a> <span class="cf">return</span> nlp(article)</span></code></pre></div>
<p>We define another helper function which performs the lemmatizing. It looks through all the words and converts them to their lemma.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="preprocess-breadtext.html#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co">#function for lemmatizing</span></span>
<span id="cb55-2"><a href="preprocess-breadtext.html#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lemmatize(sentence):</span>
<span id="cb55-3"><a href="preprocess-breadtext.html#cb55-3" aria-hidden="true" tabindex="-1"></a>    article <span class="op">=</span> <span class="st">&#39; &#39;</span>.join([word.lemma_ <span class="cf">for</span> word <span class="kw">in</span> </span>
<span id="cb55-4"><a href="preprocess-breadtext.html#cb55-4" aria-hidden="true" tabindex="-1"></a>    sentence])</span>
<span id="cb55-5"><a href="preprocess-breadtext.html#cb55-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> nlp(article)</span></code></pre></div>
<p>Now, lets see how these functions work on a small snippet of text from an article. We first print the original text, then the text after stopwords and punctuation are removed and finally after lemmatization is applied. We see how the text becomes shorter and less readable for us mere humans when these steps are applied. But for the functions in <code>spacy</code> the last text is just yummi.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="preprocess-breadtext.html#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co">#trying out the function on a single text</span></span>
<span id="cb56-2"><a href="preprocess-breadtext.html#cb56-2" aria-hidden="true" tabindex="-1"></a>article <span class="op">=</span> df.iloc[<span class="dv">28</span>,<span class="dv">3</span>]</span>
<span id="cb56-3"><a href="preprocess-breadtext.html#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Orignial Text: &quot;</span>)</span>
<span id="cb56-4"><a href="preprocess-breadtext.html#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(article[<span class="dv">0</span>:<span class="dv">582</span>]  <span class="op">+</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb56-5"><a href="preprocess-breadtext.html#cb56-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-6"><a href="preprocess-breadtext.html#cb56-6" aria-hidden="true" tabindex="-1"></a><span class="co">#removing special chars and stopwords</span></span>
<span id="cb56-7"><a href="preprocess-breadtext.html#cb56-7" aria-hidden="true" tabindex="-1"></a>article <span class="op">=</span> remove_special_chars_and_stopwords(article)</span>
<span id="cb56-8"><a href="preprocess-breadtext.html#cb56-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Stopwords and punctuation removed: &quot;</span>)</span>
<span id="cb56-9"><a href="preprocess-breadtext.html#cb56-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">str</span>(article)[<span class="dv">0</span>:<span class="dv">405</span>]  <span class="op">+</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb56-10"><a href="preprocess-breadtext.html#cb56-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-11"><a href="preprocess-breadtext.html#cb56-11" aria-hidden="true" tabindex="-1"></a><span class="co">#lemmatizing the article</span></span>
<span id="cb56-12"><a href="preprocess-breadtext.html#cb56-12" aria-hidden="true" tabindex="-1"></a>article <span class="op">=</span> lemmatize(article)</span>
<span id="cb56-13"><a href="preprocess-breadtext.html#cb56-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Lemmatization applied:&quot;</span>)</span>
<span id="cb56-14"><a href="preprocess-breadtext.html#cb56-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">str</span>(article)[<span class="dv">0</span>:<span class="dv">362</span>] <span class="op">+</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<p><img src="preprocess_breadtext.png" /></p>
<p>We now know that the helper functions do what they are supposed to do. This means that we can apply those functions to all the articles in a for-loop.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="preprocess-breadtext.html#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co">#defining index to loop over</span></span>
<span id="cb57-2"><a href="preprocess-breadtext.html#cb57-2" aria-hidden="true" tabindex="-1"></a>article_index <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb57-3"><a href="preprocess-breadtext.html#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="preprocess-breadtext.html#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="co">#defining lists for the cleaned articles</span></span>
<span id="cb57-5"><a href="preprocess-breadtext.html#cb57-5" aria-hidden="true" tabindex="-1"></a>articles_clean <span class="op">=</span> []</span>
<span id="cb57-6"><a href="preprocess-breadtext.html#cb57-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-7"><a href="preprocess-breadtext.html#cb57-7" aria-hidden="true" tabindex="-1"></a><span class="co">#looping over bread texts from all articles and running the functions on them</span></span>
<span id="cb57-8"><a href="preprocess-breadtext.html#cb57-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> article <span class="kw">in</span> df.index:</span>
<span id="cb57-9"><a href="preprocess-breadtext.html#cb57-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">#load article using index</span></span>
<span id="cb57-10"><a href="preprocess-breadtext.html#cb57-10" aria-hidden="true" tabindex="-1"></a>    article <span class="op">=</span> df.iloc[article_index,<span class="dv">3</span>]</span>
<span id="cb57-11"><a href="preprocess-breadtext.html#cb57-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-12"><a href="preprocess-breadtext.html#cb57-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#cleaning the article</span></span>
<span id="cb57-13"><a href="preprocess-breadtext.html#cb57-13" aria-hidden="true" tabindex="-1"></a>    article <span class="op">=</span> remove_special_chars_and_stopwords(article)</span>
<span id="cb57-14"><a href="preprocess-breadtext.html#cb57-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-15"><a href="preprocess-breadtext.html#cb57-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">#lemmatizing the article</span></span>
<span id="cb57-16"><a href="preprocess-breadtext.html#cb57-16" aria-hidden="true" tabindex="-1"></a>    article <span class="op">=</span> lemmatize(article)</span>
<span id="cb57-17"><a href="preprocess-breadtext.html#cb57-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-18"><a href="preprocess-breadtext.html#cb57-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">#appending the clean article to a list of clean articles</span></span>
<span id="cb57-19"><a href="preprocess-breadtext.html#cb57-19" aria-hidden="true" tabindex="-1"></a>    articles_clean.append(article)</span>
<span id="cb57-20"><a href="preprocess-breadtext.html#cb57-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-21"><a href="preprocess-breadtext.html#cb57-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">#indexing to next article</span></span>
<span id="cb57-22"><a href="preprocess-breadtext.html#cb57-22" aria-hidden="true" tabindex="-1"></a>    article_index <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb57-23"><a href="preprocess-breadtext.html#cb57-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-24"><a href="preprocess-breadtext.html#cb57-24" aria-hidden="true" tabindex="-1"></a>    <span class="co">#checking progress</span></span>
<span id="cb57-25"><a href="preprocess-breadtext.html#cb57-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(article_index)</span>
<span id="cb57-26"><a href="preprocess-breadtext.html#cb57-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-27"><a href="preprocess-breadtext.html#cb57-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-28"><a href="preprocess-breadtext.html#cb57-28" aria-hidden="true" tabindex="-1"></a><span class="co">#making a new column in df containing the cleaned bread text</span></span>
<span id="cb57-29"><a href="preprocess-breadtext.html#cb57-29" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;bread_text_preprocessed&#39;</span>] <span class="op">=</span> articles_clean</span></code></pre></div>
<p>Lastly we save it to three datasets. Otherwise the files are too large for Git.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="preprocess-breadtext.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co">#splitting into three datasets</span></span>
<span id="cb58-2"><a href="preprocess-breadtext.html#cb58-2" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> df.iloc[<span class="dv">0</span>:<span class="dv">7500</span>,]</span>
<span id="cb58-3"><a href="preprocess-breadtext.html#cb58-3" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> df.iloc[<span class="dv">7501</span>:<span class="dv">15000</span>,]</span>
<span id="cb58-4"><a href="preprocess-breadtext.html#cb58-4" aria-hidden="true" tabindex="-1"></a>df3 <span class="op">=</span> df.iloc[<span class="dv">15001</span>:<span class="dv">21113</span>, ]</span>
<span id="cb58-5"><a href="preprocess-breadtext.html#cb58-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-6"><a href="preprocess-breadtext.html#cb58-6" aria-hidden="true" tabindex="-1"></a><span class="co">#saving to three new files</span></span>
<span id="cb58-7"><a href="preprocess-breadtext.html#cb58-7" aria-hidden="true" tabindex="-1"></a>df1.to_csv(<span class="st">&quot;data/new_york_times/NYT_clean_1.csv&quot;</span>, index <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb58-8"><a href="preprocess-breadtext.html#cb58-8" aria-hidden="true" tabindex="-1"></a>df2.to_csv(<span class="st">&quot;data/new_york_times/NYT_clean_2.csv&quot;</span>, index <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb58-9"><a href="preprocess-breadtext.html#cb58-9" aria-hidden="true" tabindex="-1"></a>df3.to_csv(<span class="st">&quot;data/new_york_times/NYT_clean_3.csv&quot;</span>, index <span class="op">=</span> <span class="va">False</span>)</span></code></pre></div>
<p>All good. We are now done with cleaning, wrangling and preprocessing. We are ready for analysis!</p>

</div>



            </section>

          </div>
        </div>
      </div>
<a href="scrape-bread-text-of-articles-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="overview-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/07_cleaningbreadtext.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
