<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 15 LDA Topic Modelling | Taliban Project</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 15 LDA Topic Modelling | Taliban Project" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 15 LDA Topic Modelling | Taliban Project" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  

<meta name="author" content="Anders Havbro Hjulmand" />


<meta name="date" content="2021-12-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="overview-3.html"/>
<link rel="next" href="topic-model-interpretation-and-vizualisation.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.17/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/nouislider-7.0.10/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider-7.0.10/jquery.nouislider.min.js"></script>
<link href="libs/selectize-0.12.0/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize-0.12.0/selectize.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/proj4-2.6.2/proj4.min.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.4.1/leaflet.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Taliban Project</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure"><i class="fa fa-check"></i>Structure</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-read-the-notebook"><i class="fa fa-check"></i>How to read the notebook</a></li>
</ul></li>
<li class="part"><span><b>I New York Times</b></span></li>
<li class="chapter" data-level="1" data-path="scraping-news-articles-with-new-york-times-api.html"><a href="scraping-news-articles-with-new-york-times-api.html"><i class="fa fa-check"></i><b>1</b> Scraping News Articles with New York Times API</a></li>
<li class="chapter" data-level="2" data-path="cleaning-the-data.html"><a href="cleaning-the-data.html"><i class="fa fa-check"></i><b>2</b> Cleaning The Data</a></li>
<li class="chapter" data-level="3" data-path="scrape-bread-text-of-articles.html"><a href="scrape-bread-text-of-articles.html"><i class="fa fa-check"></i><b>3</b> Scrape bread text of articles</a>
<ul>
<li class="chapter" data-level="3.1" data-path="scrape-bread-text-of-articles.html"><a href="scrape-bread-text-of-articles.html#scraping-in-python"><i class="fa fa-check"></i><b>3.1</b> Scraping in Python</a></li>
<li class="chapter" data-level="3.2" data-path="scrape-bread-text-of-articles.html"><a href="scrape-bread-text-of-articles.html#inspecting-the-bread-text"><i class="fa fa-check"></i><b>3.2</b> Inspecting the bread text</a></li>
</ul></li>
<li class="part"><span><b>II The Guardian</b></span></li>
<li class="chapter" data-level="4" data-path="scraping-articles-form-the-guardian.html"><a href="scraping-articles-form-the-guardian.html"><i class="fa fa-check"></i><b>4</b> Scraping articles form the Guardian</a></li>
<li class="chapter" data-level="5" data-path="cleaning-the-data-1.html"><a href="cleaning-the-data-1.html"><i class="fa fa-check"></i><b>5</b> Cleaning the Data</a></li>
<li class="chapter" data-level="6" data-path="scrape-bread-text-of-articles-1.html"><a href="scrape-bread-text-of-articles-1.html"><i class="fa fa-check"></i><b>6</b> Scrape bread text of articles</a>
<ul>
<li class="chapter" data-level="6.1" data-path="scrape-bread-text-of-articles-1.html"><a href="scrape-bread-text-of-articles-1.html#scraping-in-python-1"><i class="fa fa-check"></i><b>6.1</b> Scraping in Python</a></li>
<li class="chapter" data-level="6.2" data-path="scrape-bread-text-of-articles-1.html"><a href="scrape-bread-text-of-articles-1.html#inspecting-the-bread-text-1"><i class="fa fa-check"></i><b>6.2</b> Inspecting the bread text</a></li>
</ul></li>
<li class="part"><span><b>III Preprocess breadtext</b></span></li>
<li class="chapter" data-level="7" data-path="preprocess-breadtext-for-both-datasets.html"><a href="preprocess-breadtext-for-both-datasets.html"><i class="fa fa-check"></i><b>7</b> Preprocess Breadtext for both Datasets</a></li>
<li class="part"><span><b>IV Named Entity recognition (NER)</b></span></li>
<li class="chapter" data-level="" data-path="overview-1.html"><a href="overview-1.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="overview-1.html"><a href="overview-1.html#structure-1"><i class="fa fa-check"></i>Structure</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="extracting-ners.html"><a href="extracting-ners.html"><i class="fa fa-check"></i><b>8</b> Extracting NER’s</a></li>
<li class="chapter" data-level="9" data-path="maps-vizualisations.html"><a href="maps-vizualisations.html"><i class="fa fa-check"></i><b>9</b> Maps vizualisations</a>
<ul>
<li class="chapter" data-level="9.1" data-path="maps-vizualisations.html"><a href="maps-vizualisations.html#preparing-the-data"><i class="fa fa-check"></i><b>9.1</b> Preparing the data</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="maps-vizualisations.html"><a href="maps-vizualisations.html#renaming-countries"><i class="fa fa-check"></i><b>9.1.1</b> Renaming Countries</a></li>
<li class="chapter" data-level="9.1.2" data-path="maps-vizualisations.html"><a href="maps-vizualisations.html#every-country-gets-a-row-for-every-date"><i class="fa fa-check"></i><b>9.1.2</b> Every country gets a row for every date</a></li>
<li class="chapter" data-level="9.1.3" data-path="maps-vizualisations.html"><a href="maps-vizualisations.html#making-a-unique-dataset-for-plotly-and-shiny-respectively"><i class="fa fa-check"></i><b>9.1.3</b> Making a unique dataset for Plotly and Shiny respectively</a></li>
<li class="chapter" data-level="9.1.4" data-path="maps-vizualisations.html"><a href="maps-vizualisations.html#making-a-penalized-count"><i class="fa fa-check"></i><b>9.1.4</b> Making a penalized count</a></li>
<li class="chapter" data-level="9.1.5" data-path="maps-vizualisations.html"><a href="maps-vizualisations.html#binsize"><i class="fa fa-check"></i><b>9.1.5</b> Setting up the binsize</a></li>
<li class="chapter" data-level="9.1.6" data-path="maps-vizualisations.html"><a href="maps-vizualisations.html#fixing-the-legend-scales-to-absolute-values."><i class="fa fa-check"></i><b>9.1.6</b> Fixing the legend scales to absolute values.</a></li>
<li class="chapter" data-level="9.1.7" data-path="maps-vizualisations.html"><a href="maps-vizualisations.html#making-a-dataframe-with-contrasts"><i class="fa fa-check"></i><b>9.1.7</b> Making a dataframe with contrasts</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="maps-vizualisations.html"><a href="maps-vizualisations.html#plotly-maps"><i class="fa fa-check"></i><b>9.2</b> Plotly Maps</a></li>
<li class="chapter" data-level="9.3" data-path="maps-vizualisations.html"><a href="maps-vizualisations.html#shiny-app"><i class="fa fa-check"></i><b>9.3</b> Shiny App</a></li>
<li class="chapter" data-level="9.4" data-path="maps-vizualisations.html"><a href="maps-vizualisations.html#popcircle"><i class="fa fa-check"></i><b>9.4</b> Popcircle</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="maps-vizualisations.html"><a href="maps-vizualisations.html#new-york-times"><i class="fa fa-check"></i><b>9.4.1</b> New York Times</a></li>
<li class="chapter" data-level="9.4.2" data-path="maps-vizualisations.html"><a href="maps-vizualisations.html#the-guardian"><i class="fa fa-check"></i><b>9.4.2</b> The Guardian</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html"><i class="fa fa-check"></i><b>10</b> Persons Vizualisation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#standardize-to-hits-pr.-article-and-grouping-by-month"><i class="fa fa-check"></i><b>10.1</b> Standardize to hits pr. article and grouping by month</a></li>
<li class="chapter" data-level="10.2" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#color-palettes"><i class="fa fa-check"></i><b>10.2</b> Color Palettes</a></li>
<li class="chapter" data-level="10.3" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#united-states-presidents"><i class="fa fa-check"></i><b>10.3</b> United States Presidents</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#summary-plot"><i class="fa fa-check"></i><b>10.3.1</b> Summary plot</a></li>
<li class="chapter" data-level="10.3.2" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#george-w.-bush"><i class="fa fa-check"></i><b>10.3.2</b> George W. Bush</a></li>
<li class="chapter" data-level="10.3.3" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#barack-obama"><i class="fa fa-check"></i><b>10.3.3</b> Barack Obama</a></li>
<li class="chapter" data-level="10.3.4" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#donald-trump"><i class="fa fa-check"></i><b>10.3.4</b> Donald Trump</a></li>
<li class="chapter" data-level="10.3.5" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#combined-plots"><i class="fa fa-check"></i><b>10.3.5</b> Combined Plots</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#british-prime-ministers"><i class="fa fa-check"></i><b>10.4</b> British Prime Ministers</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#summary-plot-1"><i class="fa fa-check"></i><b>10.4.1</b> Summary plot</a></li>
<li class="chapter" data-level="10.4.2" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#tony-blair"><i class="fa fa-check"></i><b>10.4.2</b> Tony Blair</a></li>
<li class="chapter" data-level="10.4.3" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#david-cameron"><i class="fa fa-check"></i><b>10.4.3</b> David Cameron</a></li>
<li class="chapter" data-level="10.4.4" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#boris-johnson"><i class="fa fa-check"></i><b>10.4.4</b> Boris Johnson</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#afghanistan-presidents"><i class="fa fa-check"></i><b>10.5</b> Afghanistan Presidents</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#summary-plot-2"><i class="fa fa-check"></i><b>10.5.1</b> Summary plot</a></li>
<li class="chapter" data-level="10.5.2" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#hamid-karzai"><i class="fa fa-check"></i><b>10.5.2</b> Hamid Karzai</a></li>
<li class="chapter" data-level="10.5.3" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#ashraf-ghani"><i class="fa fa-check"></i><b>10.5.3</b> Ashraf Ghani</a></li>
<li class="chapter" data-level="10.5.4" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#combined-plots-1"><i class="fa fa-check"></i><b>10.5.4</b> Combined Plots</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#other-persons"><i class="fa fa-check"></i><b>10.6</b> Other Persons</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#summary-plot-3"><i class="fa fa-check"></i><b>10.6.1</b> Summary plot</a></li>
<li class="chapter" data-level="10.6.2" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#osama-bin-laden"><i class="fa fa-check"></i><b>10.6.2</b> Osama bin Laden</a></li>
<li class="chapter" data-level="10.6.3" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#saddam-hussein"><i class="fa fa-check"></i><b>10.6.3</b> Saddam Hussein</a></li>
<li class="chapter" data-level="10.6.4" data-path="persons-vizualisation.html"><a href="persons-vizualisation.html#combined-plots-2"><i class="fa fa-check"></i><b>10.6.4</b> Combined Plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="organisations-vizualisations.html"><a href="organisations-vizualisations.html"><i class="fa fa-check"></i><b>11</b> Organisations Vizualisations</a>
<ul>
<li class="chapter" data-level="11.1" data-path="organisations-vizualisations.html"><a href="organisations-vizualisations.html#standardize-names-of-organisations"><i class="fa fa-check"></i><b>11.1</b> Standardize names of organisations</a></li>
<li class="chapter" data-level="11.2" data-path="organisations-vizualisations.html"><a href="organisations-vizualisations.html#standardize-to-hits-pr.-article-and-grouping-by-month-1"><i class="fa fa-check"></i><b>11.2</b> Standardize to hits pr. article and grouping by month</a></li>
<li class="chapter" data-level="11.3" data-path="organisations-vizualisations.html"><a href="organisations-vizualisations.html#color-palettes-1"><i class="fa fa-check"></i><b>11.3</b> Color Palettes</a></li>
<li class="chapter" data-level="11.4" data-path="organisations-vizualisations.html"><a href="organisations-vizualisations.html#summary-plot-4"><i class="fa fa-check"></i><b>11.4</b> Summary plot</a></li>
<li class="chapter" data-level="11.5" data-path="organisations-vizualisations.html"><a href="organisations-vizualisations.html#nato"><i class="fa fa-check"></i><b>11.5</b> NATO</a></li>
<li class="chapter" data-level="11.6" data-path="organisations-vizualisations.html"><a href="organisations-vizualisations.html#taliban"><i class="fa fa-check"></i><b>11.6</b> Taliban</a></li>
<li class="chapter" data-level="11.7" data-path="organisations-vizualisations.html"><a href="organisations-vizualisations.html#al-qaeda"><i class="fa fa-check"></i><b>11.7</b> Al Qaeda</a></li>
<li class="chapter" data-level="11.8" data-path="organisations-vizualisations.html"><a href="organisations-vizualisations.html#hamas"><i class="fa fa-check"></i><b>11.8</b> Hamas</a></li>
<li class="chapter" data-level="11.9" data-path="organisations-vizualisations.html"><a href="organisations-vizualisations.html#hezbollah"><i class="fa fa-check"></i><b>11.9</b> Hezbollah</a></li>
<li class="chapter" data-level="11.10" data-path="organisations-vizualisations.html"><a href="organisations-vizualisations.html#combined-plots-for-all-key-organisations"><i class="fa fa-check"></i><b>11.10</b> Combined Plots for all Key Organisations</a>
<ul>
<li class="chapter" data-level="11.10.1" data-path="organisations-vizualisations.html"><a href="organisations-vizualisations.html#new-york-times-5"><i class="fa fa-check"></i><b>11.10.1</b> New York Times</a></li>
<li class="chapter" data-level="11.10.2" data-path="organisations-vizualisations.html"><a href="organisations-vizualisations.html#the-guardian-5"><i class="fa fa-check"></i><b>11.10.2</b> The Guardian</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="nouns-verbs-and-adjectives-vizualisation.html"><a href="nouns-verbs-and-adjectives-vizualisation.html"><i class="fa fa-check"></i><b>12</b> Nouns, Verbs and Adjectives Vizualisation</a>
<ul>
<li class="chapter" data-level="12.1" data-path="nouns-verbs-and-adjectives-vizualisation.html"><a href="nouns-verbs-and-adjectives-vizualisation.html#color-palettes-2"><i class="fa fa-check"></i><b>12.1</b> Color Palettes</a></li>
<li class="chapter" data-level="12.2" data-path="nouns-verbs-and-adjectives-vizualisation.html"><a href="nouns-verbs-and-adjectives-vizualisation.html#top-5-nouns"><i class="fa fa-check"></i><b>12.2</b> Top 5 Nouns</a></li>
<li class="chapter" data-level="12.3" data-path="nouns-verbs-and-adjectives-vizualisation.html"><a href="nouns-verbs-and-adjectives-vizualisation.html#top-5-verbs"><i class="fa fa-check"></i><b>12.3</b> Top 5 Verbs</a></li>
<li class="chapter" data-level="12.4" data-path="nouns-verbs-and-adjectives-vizualisation.html"><a href="nouns-verbs-and-adjectives-vizualisation.html#top-5-adjectives"><i class="fa fa-check"></i><b>12.4</b> Top 5 Adjectives</a></li>
</ul></li>
<li class="part"><span><b>V Sentiment Analysis</b></span></li>
<li class="chapter" data-level="" data-path="overview-2.html"><a href="overview-2.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="13" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html"><i class="fa fa-check"></i><b>13</b> Sentiment Analysis</a></li>
<li class="chapter" data-level="14" data-path="sentiment-vizualisations.html"><a href="sentiment-vizualisations.html"><i class="fa fa-check"></i><b>14</b> Sentiment Vizualisations</a>
<ul>
<li class="chapter" data-level="14.1" data-path="sentiment-vizualisations.html"><a href="sentiment-vizualisations.html#data-wrangling"><i class="fa fa-check"></i><b>14.1</b> Data wrangling</a></li>
<li class="chapter" data-level="14.2" data-path="sentiment-vizualisations.html"><a href="sentiment-vizualisations.html#color-palettes-3"><i class="fa fa-check"></i><b>14.2</b> Color Palettes</a></li>
<li class="chapter" data-level="14.3" data-path="sentiment-vizualisations.html"><a href="sentiment-vizualisations.html#polarity"><i class="fa fa-check"></i><b>14.3</b> Polarity</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="sentiment-vizualisations.html"><a href="sentiment-vizualisations.html#summary-stats"><i class="fa fa-check"></i><b>14.3.1</b> Summary stats</a></li>
<li class="chapter" data-level="14.3.2" data-path="sentiment-vizualisations.html"><a href="sentiment-vizualisations.html#timeline"><i class="fa fa-check"></i><b>14.3.2</b> Timeline</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="sentiment-vizualisations.html"><a href="sentiment-vizualisations.html#subjectivity"><i class="fa fa-check"></i><b>14.4</b> Subjectivity</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="sentiment-vizualisations.html"><a href="sentiment-vizualisations.html#summary-stats-1"><i class="fa fa-check"></i><b>14.4.1</b> Summary stats</a></li>
<li class="chapter" data-level="14.4.2" data-path="sentiment-vizualisations.html"><a href="sentiment-vizualisations.html#timeline-1"><i class="fa fa-check"></i><b>14.4.2</b> Timeline</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VI LDA Topic Modelling</b></span></li>
<li class="chapter" data-level="" data-path="overview-3.html"><a href="overview-3.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="overview-3.html"><a href="overview-3.html#what-is-an-lda-topic-model"><i class="fa fa-check"></i>What is an LDA topic model?</a></li>
<li class="chapter" data-level="" data-path="overview-3.html"><a href="overview-3.html#example"><i class="fa fa-check"></i>Example</a></li>
<li class="chapter" data-level="" data-path="overview-3.html"><a href="overview-3.html#the-goal-of-lda-topic-model"><i class="fa fa-check"></i>The goal of LDA topic model</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html"><i class="fa fa-check"></i><b>15</b> LDA Topic Modelling</a>
<ul>
<li class="chapter" data-level="15.1" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#packages-and-data"><i class="fa fa-check"></i><b>15.1</b> Packages and Data</a></li>
<li class="chapter" data-level="15.2" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#preprocessing"><i class="fa fa-check"></i><b>15.2</b> Preprocessing</a></li>
<li class="chapter" data-level="15.3" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#bigrams-and-trigrams"><i class="fa fa-check"></i><b>15.3</b> Bigrams and Trigrams</a></li>
<li class="chapter" data-level="15.4" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#tf-idf-removal"><i class="fa fa-check"></i><b>15.4</b> TF-IDF Removal</a></li>
<li class="chapter" data-level="15.5" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#base-topic-model"><i class="fa fa-check"></i><b>15.5</b> Base topic model</a></li>
<li class="chapter" data-level="15.6" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#selecting-the-number-of-topics-based-on-coherence-score"><i class="fa fa-check"></i><b>15.6</b> Selecting the number of topics based on coherence score</a>
<ul>
<li class="chapter" data-level="15.6.1" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#selecting-number-of-topics-for-new-york-times"><i class="fa fa-check"></i><b>15.6.1</b> Selecting number of topics for New York Times</a></li>
<li class="chapter" data-level="15.6.2" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#selecting-number-of-topics-for-the-guardian"><i class="fa fa-check"></i><b>15.6.2</b> Selecting number of topics for The Guardian</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#building-the-topic-models"><i class="fa fa-check"></i><b>15.7</b> Building the topic models</a>
<ul>
<li class="chapter" data-level="15.7.1" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#new-york-times-topic-model"><i class="fa fa-check"></i><b>15.7.1</b> New York Times topic model</a></li>
<li class="chapter" data-level="15.7.2" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#the-guardian-topic-model"><i class="fa fa-check"></i><b>15.7.2</b> The Guardian topic model</a></li>
</ul></li>
<li class="chapter" data-level="15.8" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#assigning-one-topic-to-each-article"><i class="fa fa-check"></i><b>15.8</b> Assigning one topic to each article</a>
<ul>
<li class="chapter" data-level="15.8.1" data-path="lda-topic-modelling.html"><a href="lda-topic-modelling.html#evaluating-the-assignment-of-one-article"><i class="fa fa-check"></i><b>15.8.1</b> Evaluating the assignment of one article</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="topic-model-interpretation-and-vizualisation.html"><a href="topic-model-interpretation-and-vizualisation.html"><i class="fa fa-check"></i><b>16</b> Topic Model Interpretation and Vizualisation</a>
<ul>
<li class="chapter" data-level="16.1" data-path="topic-model-interpretation-and-vizualisation.html"><a href="topic-model-interpretation-and-vizualisation.html#plotting-topic-prevalence"><i class="fa fa-check"></i><b>16.1</b> Plotting topic prevalence</a></li>
<li class="chapter" data-level="16.2" data-path="topic-model-interpretation-and-vizualisation.html"><a href="topic-model-interpretation-and-vizualisation.html#plotting-topic-prevalence-over-time"><i class="fa fa-check"></i><b>16.2</b> Plotting topic prevalence over time</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="topic-model-interpretation-and-vizualisation.html"><a href="topic-model-interpretation-and-vizualisation.html#data-wrangling-1"><i class="fa fa-check"></i><b>16.2.1</b> Data Wrangling</a></li>
<li class="chapter" data-level="16.2.2" data-path="topic-model-interpretation-and-vizualisation.html"><a href="topic-model-interpretation-and-vizualisation.html#plots"><i class="fa fa-check"></i><b>16.2.2</b> Plots</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="topic-model-interpretation-and-vizualisation.html"><a href="topic-model-interpretation-and-vizualisation.html#does-topics-differ-in-polarity-and-subjectivity"><i class="fa fa-check"></i><b>16.3</b> Does topics differ in polarity and subjectivity?</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="topic-model-interpretation-and-vizualisation.html"><a href="topic-model-interpretation-and-vizualisation.html#polarity-1"><i class="fa fa-check"></i><b>16.3.1</b> Polarity</a></li>
<li class="chapter" data-level="16.3.2" data-path="topic-model-interpretation-and-vizualisation.html"><a href="topic-model-interpretation-and-vizualisation.html#subjectivity-1"><i class="fa fa-check"></i><b>16.3.2</b> Subjectivity</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VII Miscellaneous</b></span></li>
<li class="chapter" data-level="17" data-path="miscellaneous-plots.html"><a href="miscellaneous-plots.html"><i class="fa fa-check"></i><b>17</b> Miscellaneous Plots</a></li>
<li class="chapter" data-level="18" data-path="gender-dataset-for-further-analysis.html"><a href="gender-dataset-for-further-analysis.html"><i class="fa fa-check"></i><b>18</b> Gender Dataset for further analysis</a>
<ul>
<li class="chapter" data-level="18.1" data-path="gender-dataset-for-further-analysis.html"><a href="gender-dataset-for-further-analysis.html#dataset-with-authors"><i class="fa fa-check"></i><b>18.1</b> Dataset with authors</a></li>
<li class="chapter" data-level="18.2" data-path="gender-dataset-for-further-analysis.html"><a href="gender-dataset-for-further-analysis.html#comparing-the-datasets"><i class="fa fa-check"></i><b>18.2</b> Comparing the datasets</a></li>
<li class="chapter" data-level="18.3" data-path="gender-dataset-for-further-analysis.html"><a href="gender-dataset-for-further-analysis.html#adding-gender-information-to-nyt_aut"><i class="fa fa-check"></i><b>18.3</b> Adding gender information to <code>NYT_aut</code></a></li>
</ul></li>
<li class="part"><span><b>VIII References</b></span></li>
<li class="chapter" data-level="19" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>19</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">See Github Repo</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Taliban Project</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lda-topic-modelling" class="section level1" number="15">
<h1><span class="header-section-number">Chapter 15</span> LDA Topic Modelling</h1>
<style>
div.green { background-color:#93c47d; border-radius: 5px; padding: 20px;}
</style>
<div class="green">
<p>Part of this chapter is written in Python. To see the original file go to the folder python_scripts/.</p>
</div>
<style>
div.blue { background-color:#76a5af; border-radius: 5px; padding: 20px;}
</style>
<div class="blue">
<p>All the code in the chapter is run on both df_NYT and df_guardian but some of the code is only shown for df_nyt.</p>
</div>
<p>In this Chapter we are going to make a LDA topic model for the dataset <code>df_nyt</code> and <code>df_guardian</code>.</p>
<div id="packages-and-data" class="section level2" number="15.1">
<h2><span class="header-section-number">15.1</span> Packages and Data</h2>
<p>Lets get to the code. We load a bunch of packages. Importantly, we will use a new library called <code>gensim</code> which is used for topic modelling. We also use <code>spaCy</code> and <code>pyLDAvis</code> which is used for vizualizing the model output.</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb230-1"><a href="lda-topic-modelling.html#cb230-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb230-2"><a href="lda-topic-modelling.html#cb230-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb230-3"><a href="lda-topic-modelling.html#cb230-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> glob</span>
<span id="cb230-4"><a href="lda-topic-modelling.html#cb230-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb230-5"><a href="lda-topic-modelling.html#cb230-5" aria-hidden="true" tabindex="-1"></a><span class="co">#Gensim</span></span>
<span id="cb230-6"><a href="lda-topic-modelling.html#cb230-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim</span>
<span id="cb230-7"><a href="lda-topic-modelling.html#cb230-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim.corpora <span class="im">as</span> corpora</span>
<span id="cb230-8"><a href="lda-topic-modelling.html#cb230-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.utils <span class="im">import</span> simple_preprocess</span>
<span id="cb230-9"><a href="lda-topic-modelling.html#cb230-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> CoherenceModel</span>
<span id="cb230-10"><a href="lda-topic-modelling.html#cb230-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> TfidfModel</span>
<span id="cb230-11"><a href="lda-topic-modelling.html#cb230-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> CoherenceModel</span>
<span id="cb230-12"><a href="lda-topic-modelling.html#cb230-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb230-13"><a href="lda-topic-modelling.html#cb230-13" aria-hidden="true" tabindex="-1"></a><span class="co">#spacy</span></span>
<span id="cb230-14"><a href="lda-topic-modelling.html#cb230-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb230-15"><a href="lda-topic-modelling.html#cb230-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb230-16"><a href="lda-topic-modelling.html#cb230-16" aria-hidden="true" tabindex="-1"></a><span class="co">#vis</span></span>
<span id="cb230-17"><a href="lda-topic-modelling.html#cb230-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyLDAvis</span>
<span id="cb230-18"><a href="lda-topic-modelling.html#cb230-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyLDAvis.gensim_models</span></code></pre></div>
<p>Then we load the dataset containing the articles.</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb231-1"><a href="lda-topic-modelling.html#cb231-1" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> pd.read_csv(<span class="st">&quot;data/new_york_times/NYT_clean_1.csv&quot;</span>)</span>
<span id="cb231-2"><a href="lda-topic-modelling.html#cb231-2" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> pd.read_csv(<span class="st">&quot;data/new_york_times/NYT_clean_2.csv&quot;</span>)</span>
<span id="cb231-3"><a href="lda-topic-modelling.html#cb231-3" aria-hidden="true" tabindex="-1"></a>df3 <span class="op">=</span> pd.read_csv(<span class="st">&quot;data/new_york_times/NYT_clean_3.csv&quot;</span>)</span>
<span id="cb231-4"><a href="lda-topic-modelling.html#cb231-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb231-5"><a href="lda-topic-modelling.html#cb231-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.concat([df1, df2, df3])</span></code></pre></div>
</div>
<div id="preprocessing" class="section level2" number="15.2">
<h2><span class="header-section-number">15.2</span> Preprocessing</h2>
<p>Although the bread text of all the articles is already preprocessed (lemmatization, removal of stopwords and removal of punctuation) we still need a little bit of preprocessing to make the LDA topic model. Here we define a helper function that break down the articles by individual words and apply a function called <code>simple_preprocess</code> from <code>gensim</code>.</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb232-1"><a href="lda-topic-modelling.html#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gen_words(texts):</span>
<span id="cb232-2"><a href="lda-topic-modelling.html#cb232-2" aria-hidden="true" tabindex="-1"></a>    final <span class="op">=</span> []</span>
<span id="cb232-3"><a href="lda-topic-modelling.html#cb232-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> text <span class="kw">in</span> texts:</span>
<span id="cb232-4"><a href="lda-topic-modelling.html#cb232-4" aria-hidden="true" tabindex="-1"></a>        new <span class="op">=</span> gensim.utils.simple_preprocess(text)</span>
<span id="cb232-5"><a href="lda-topic-modelling.html#cb232-5" aria-hidden="true" tabindex="-1"></a>        final.append(new)</span>
<span id="cb232-6"><a href="lda-topic-modelling.html#cb232-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (final)</span></code></pre></div>
<p>We use the function on the articles from the dataset, to generate a list of all the articles broken down into words called <code>data_words</code>.</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb233-1"><a href="lda-topic-modelling.html#cb233-1" aria-hidden="true" tabindex="-1"></a>data_words <span class="op">=</span> gen_words(df[<span class="st">&quot;articles_clean&quot;</span>])</span></code></pre></div>
<p>Now lets see what this helper function actually did.</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb234-1"><a href="lda-topic-modelling.html#cb234-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Before applying the helper function gen_words: </span><span class="ch">\n</span><span class="st">&quot;</span> <span class="op">+</span> <span class="bu">str</span>(df.iloc[<span class="dv">0</span>,<span class="dv">4</span>][<span class="dv">0</span>:<span class="dv">142</span>]))</span>
<span id="cb234-2"><a href="lda-topic-modelling.html#cb234-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">After applying the helper function gen_words: </span><span class="ch">\n</span><span class="st">&quot;</span> <span class="op">+</span> <span class="bu">str</span>(data_words[<span class="dv">0</span>][<span class="dv">0</span>:<span class="dv">20</span>]))</span></code></pre></div>
<div class="figure">
<img src="images/preprocess_gensim.JPG" alt="" />
<p class="caption">Gensim Preprocessing</p>
</div>
<p>This is how the data looks before and after applying the helper function <code>gen_words</code>. Before application we see that the data is simply a collection of words. After application we see that all the words have been split into their element in a list. So now each article is a list where the elements of that list is the individual words.</p>
</div>
<div id="bigrams-and-trigrams" class="section level2" number="15.3">
<h2><span class="header-section-number">15.3</span> Bigrams and Trigrams</h2>
<p>Next up we make <em>bigrams</em> and <em>trigrams</em>. Bigrams are 2 consecutive word in a sentence that occur with a high frequency. Trigrams are 3 consecutive words in a sentence that occur with a high frequency. Lets take an example where we have the following sentences:</p>
<ol style="list-style-type: decimal">
<li>The connection of devices is <em>wireless</em>.</li>
<li>The <em>speakers</em> have a solid bass.</li>
<li>The <em>wireless speakers</em> are expensive.</li>
</ol>
<p>In sentence 1 the word <em>wireless</em> occurs by itself. Similarly, in sentence 2 the word <em>speakers</em> occur by itself. However, in sentence 3 the two words occur together in a meaningful way to form a single unit. If <em>wireless speakers</em> occurs with a high enough frequency, we call it a bigram.</p>
<p>Now we get to the code. We look for bigrams using the function <code>Phrases</code> from the library <code>gensim</code>. This function takes <code>data_words</code> which we created earlier and <code>min_count</code> which determines the minimum number of times two words need to occur together to be considered a bigram. It also takes <code>threshold</code> which determines the the number of phrases that are found. A higher threshold will result in fewer bigrams. It is important to adjust the threshold so it doesn’t pick up too few or too many bigrams. We also look for trigrams using the same function but this time using the <code>bigram_phrases</code> as input.</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb235-1"><a href="lda-topic-modelling.html#cb235-1" aria-hidden="true" tabindex="-1"></a>bigram_phrases <span class="op">=</span> gensim.models.Phrases(data_words, min_count<span class="op">=</span><span class="dv">5</span>, threshold<span class="op">=</span><span class="dv">80</span>)</span>
<span id="cb235-2"><a href="lda-topic-modelling.html#cb235-2" aria-hidden="true" tabindex="-1"></a>trigram_phrases <span class="op">=</span> gensim.models.Phrases(bigram_phrases[data_words], threshold<span class="op">=</span><span class="dv">80</span>)</span></code></pre></div>
<p>Then we create the objects <code>bigram</code> and <code>trigram</code>.</p>
<div class="sourceCode" id="cb236"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb236-1"><a href="lda-topic-modelling.html#cb236-1" aria-hidden="true" tabindex="-1"></a>bigram <span class="op">=</span> gensim.models.phrases.Phraser(bigram_phrases)</span>
<span id="cb236-2"><a href="lda-topic-modelling.html#cb236-2" aria-hidden="true" tabindex="-1"></a>trigram <span class="op">=</span> gensim.models.phrases.Phraser(trigram_phrases)</span></code></pre></div>
<p>Next we make two functions that add the bigrams and trigrams into <code>data_words</code>.</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb237-1"><a href="lda-topic-modelling.html#cb237-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_bigrams(texts):</span>
<span id="cb237-2"><a href="lda-topic-modelling.html#cb237-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>([bigram[doc] <span class="cf">for</span> doc <span class="kw">in</span> texts])</span>
<span id="cb237-3"><a href="lda-topic-modelling.html#cb237-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb237-4"><a href="lda-topic-modelling.html#cb237-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_trigrams(texts):</span>
<span id="cb237-5"><a href="lda-topic-modelling.html#cb237-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ([trigram[bigram[doc]] <span class="cf">for</span> doc <span class="kw">in</span> texts])</span></code></pre></div>
<p>Here we apply the functions.</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb238-1"><a href="lda-topic-modelling.html#cb238-1" aria-hidden="true" tabindex="-1"></a>data_bigrams <span class="op">=</span> make_bigrams(data_words)</span>
<span id="cb238-2"><a href="lda-topic-modelling.html#cb238-2" aria-hidden="true" tabindex="-1"></a>data_bigrams_trigrams <span class="op">=</span> make_trigrams(data_bigrams)</span></code></pre></div>
<p>Now lets see which bigrams and trigrams have been picked up.</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb239-1"><a href="lda-topic-modelling.html#cb239-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Without bigrams and trigrams:</span><span class="ch">\n</span><span class="st">&quot;</span> <span class="op">+</span> <span class="bu">str</span>(data_words[<span class="dv">1067</span>][<span class="dv">0</span>:<span class="dv">100</span>]))</span>
<span id="cb239-2"><a href="lda-topic-modelling.html#cb239-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;</span><span class="ch">\n</span><span class="st">With bigrams and trigrams:</span><span class="ch">\n</span><span class="st">&quot;</span> <span class="op">+</span> <span class="bu">str</span>(data_bigrams_trigrams[<span class="dv">1067</span>][<span class="dv">0</span>:<span class="dv">100</span>]))</span></code></pre></div>
<div class="figure">
<img src="images/bigram_trigram_example.JPG" alt="" />
<p class="caption">Bigrams and Trigrams</p>
</div>
<p>In the first section without bigrams and trigrams we see that the data appears as individual units. In the second section we see the same words as before but we also see bigrams and trigrams highlighted by a yellow color.</p>
</div>
<div id="tf-idf-removal" class="section level2" number="15.4">
<h2><span class="header-section-number">15.4</span> TF-IDF Removal</h2>
<p>TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. It is a way of ranking how important a word is to a document in a collection of documents. TF-IDF is short for <em>term frequency - inverse document frequency</em>.
Term frequency is the frequency of a word in a document. You simply count how many times a word appears in a document. Inverse document frequency indicates how common or rare a word is in the entire collection of documents. The closer to 0, the more common a word is in the collection of documents. Multiplying these two numbers results in the TF-IDF score for a word. The higher the score, the more relevant a word is to a particular document.</p>
<p>TF-IDF has many applications. Here i use it to remove words that don’t add any meaningful value to the topic model. I am going to remove frequently occurring words such as <em>say</em>. The reason we do this is that some words are so generic that they do not add any meaningful information to the topics in the topic model. The result of this removal is that our topics will be more distinct, i.e. there will be less overlap between topics.</p>
<p>We start be defining the object <code>texts</code> which is the list of words of all articles containing bigrams and trigrams.</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb240-1"><a href="lda-topic-modelling.html#cb240-1" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> data_bigrams_trigrams</span></code></pre></div>
<p>Then we make a dictionary from <code>texts</code> which counts the occurrence of words in each article.</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb241-1"><a href="lda-topic-modelling.html#cb241-1" aria-hidden="true" tabindex="-1"></a>id2word <span class="op">=</span> corpora.Dictionary(texts)</span></code></pre></div>
<p>We convert all the documents into a bag of words.</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb242-1"><a href="lda-topic-modelling.html#cb242-1" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> [id2word.doc2bow(text) <span class="cf">for</span> text <span class="kw">in</span> texts]</span></code></pre></div>
<p>We make the TD-IDF model and a variable called <code>low_value</code> which determines the threshold where words are removed. A higher threshold will result in more words being removed.</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb243-1"><a href="lda-topic-modelling.html#cb243-1" aria-hidden="true" tabindex="-1"></a>tfidf <span class="op">=</span> TfidfModel(corpus, id2word<span class="op">=</span>id2word)</span>
<span id="cb243-2"><a href="lda-topic-modelling.html#cb243-2" aria-hidden="true" tabindex="-1"></a>low_value <span class="op">=</span> <span class="fl">0.03</span></span></code></pre></div>
<p>Here is a large chunk of code, but don’t sweat it. It basically looks for words that are so generic across all documents that they don’t add any meaningful value to the topic model. The end product is a new corpus where these generic words are removed.</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb244-1"><a href="lda-topic-modelling.html#cb244-1" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> []</span>
<span id="cb244-2"><a href="lda-topic-modelling.html#cb244-2" aria-hidden="true" tabindex="-1"></a>words_missing_in_tfidf <span class="op">=</span> []</span>
<span id="cb244-3"><a href="lda-topic-modelling.html#cb244-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb244-4"><a href="lda-topic-modelling.html#cb244-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(corpus)):</span>
<span id="cb244-5"><a href="lda-topic-modelling.html#cb244-5" aria-hidden="true" tabindex="-1"></a>    bow <span class="op">=</span> corpus[i]</span>
<span id="cb244-6"><a href="lda-topic-modelling.html#cb244-6" aria-hidden="true" tabindex="-1"></a>    low_value_words <span class="op">=</span> [] <span class="co">#reinitialize to be safe. You can skip this.</span></span>
<span id="cb244-7"><a href="lda-topic-modelling.html#cb244-7" aria-hidden="true" tabindex="-1"></a>    tfidf_ids <span class="op">=</span> [<span class="bu">id</span> <span class="cf">for</span> <span class="bu">id</span>, value <span class="kw">in</span> tfidf[bow]]</span>
<span id="cb244-8"><a href="lda-topic-modelling.html#cb244-8" aria-hidden="true" tabindex="-1"></a>    bow_ids <span class="op">=</span> [<span class="bu">id</span> <span class="cf">for</span> <span class="bu">id</span>, value <span class="kw">in</span> bow]</span>
<span id="cb244-9"><a href="lda-topic-modelling.html#cb244-9" aria-hidden="true" tabindex="-1"></a>    low_value_words <span class="op">=</span> [<span class="bu">id</span> <span class="cf">for</span> <span class="bu">id</span>, value <span class="kw">in</span> tfidf[bow] <span class="cf">if</span> value <span class="op">&lt;</span> low_value]</span>
<span id="cb244-10"><a href="lda-topic-modelling.html#cb244-10" aria-hidden="true" tabindex="-1"></a>    drops <span class="op">=</span> low_value_words<span class="op">+</span>words_missing_in_tfidf</span>
<span id="cb244-11"><a href="lda-topic-modelling.html#cb244-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item <span class="kw">in</span> drops:</span>
<span id="cb244-12"><a href="lda-topic-modelling.html#cb244-12" aria-hidden="true" tabindex="-1"></a>        words.append(id2word[item])</span>
<span id="cb244-13"><a href="lda-topic-modelling.html#cb244-13" aria-hidden="true" tabindex="-1"></a>    words_missing_in_tfidf <span class="op">=</span> [<span class="bu">id</span> <span class="cf">for</span> <span class="bu">id</span> <span class="kw">in</span> bow_ids <span class="cf">if</span> <span class="bu">id</span> <span class="kw">not</span> <span class="kw">in</span> tfidf_ids] <span class="co"># The words with tf-idf score 0 will be missing</span></span>
<span id="cb244-14"><a href="lda-topic-modelling.html#cb244-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb244-15"><a href="lda-topic-modelling.html#cb244-15" aria-hidden="true" tabindex="-1"></a>    new_bow <span class="op">=</span> [b <span class="cf">for</span> b <span class="kw">in</span> bow <span class="cf">if</span> b[<span class="dv">0</span>] <span class="kw">not</span> <span class="kw">in</span> low_value_words <span class="kw">and</span> b[<span class="dv">0</span>] <span class="kw">not</span> <span class="kw">in</span> words_missing_in_tfidf]</span>
<span id="cb244-16"><a href="lda-topic-modelling.html#cb244-16" aria-hidden="true" tabindex="-1"></a>    corpus[i] <span class="op">=</span> new_bow</span></code></pre></div>
<p>So now our texts contain bigrams and trigrams and frequently occurring words have been removed. Now to the fun part.</p>
</div>
<div id="base-topic-model" class="section level2" number="15.5">
<h2><span class="header-section-number">15.5</span> Base topic model</h2>
<p>Now we can finally create the LDA topic model using <code>gensim</code>. The two main inputs to the topic model are our dictionary/id2word and corpus which we created earlier. We can adjust many hyperparameters such as <code>random_state</code> and <code>alpha</code> to make the model perform optimally. We can also choose the number of topics in <code>num_topics</code>. Here i just choose 10 topics.</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb245-1"><a href="lda-topic-modelling.html#cb245-1" aria-hidden="true" tabindex="-1"></a>lda_model <span class="op">=</span> gensim.models.ldamodel.LdaModel(corpus <span class="op">=</span> corpus,</span>
<span id="cb245-2"><a href="lda-topic-modelling.html#cb245-2" aria-hidden="true" tabindex="-1"></a>                                            id2word <span class="op">=</span> id2word,</span>
<span id="cb245-3"><a href="lda-topic-modelling.html#cb245-3" aria-hidden="true" tabindex="-1"></a>                                            num_topics <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb245-4"><a href="lda-topic-modelling.html#cb245-4" aria-hidden="true" tabindex="-1"></a>                                            random_state <span class="op">=</span> <span class="dv">100</span>,</span>
<span id="cb245-5"><a href="lda-topic-modelling.html#cb245-5" aria-hidden="true" tabindex="-1"></a>                                            update_every <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb245-6"><a href="lda-topic-modelling.html#cb245-6" aria-hidden="true" tabindex="-1"></a>                                            chunksize <span class="op">=</span> <span class="dv">100</span>,</span>
<span id="cb245-7"><a href="lda-topic-modelling.html#cb245-7" aria-hidden="true" tabindex="-1"></a>                                            passes <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb245-8"><a href="lda-topic-modelling.html#cb245-8" aria-hidden="true" tabindex="-1"></a>                                            alpha <span class="op">=</span> <span class="st">&quot;auto&quot;</span>,</span>
<span id="cb245-9"><a href="lda-topic-modelling.html#cb245-9" aria-hidden="true" tabindex="-1"></a>                                            )</span></code></pre></div>
<p>Now we can visualize the model. If you want to play around with it yourself go to the original python script.</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb246-1"><a href="lda-topic-modelling.html#cb246-1" aria-hidden="true" tabindex="-1"></a>pyLDAvis.enable_notebook()</span>
<span id="cb246-2"><a href="lda-topic-modelling.html#cb246-2" aria-hidden="true" tabindex="-1"></a>vis <span class="op">=</span> pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds <span class="op">=</span> <span class="st">&quot;mmds&quot;</span>, R<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb246-3"><a href="lda-topic-modelling.html#cb246-3" aria-hidden="true" tabindex="-1"></a>vis</span></code></pre></div>
<div class="figure">
<img src="images/base_nyt_topic_model.JPG" alt="" />
<p class="caption">Base Topic Model for New York Times</p>
</div>
<p>In the base topic model for New York Times we see that 10 topics have been created. On the left we see topics 1-10 plotted on a 2-dimensional space. The size of the circles indicate the prevalence of the topic throughout the articles. Larger means more prevalent. We see that the topics are well spread throughout the 2-dimensional space and that there is no obvious overlap between topics. On the right we see the top-words for topic number 1.</p>
</div>
<div id="selecting-the-number-of-topics-based-on-coherence-score" class="section level2" number="15.6">
<h2><span class="header-section-number">15.6</span> Selecting the number of topics based on coherence score</h2>
<p>There are many ways of evaluating an LDA topic model to see if it performs as we intend it to. Likewise there are many hyperparameters that can evaluated and tuned accordingly such as <em>alpha</em> and <em>beta</em>. Here i will evaluate the model by choosing the number of topics using something called a coherence score. There are many coherence measures, here I use one called <code>C_v</code>.</p>
<p>In the next section of code I compute the coherence score for topic models with a varying number of topics to see which number of topics is the optimal.</p>
<p>I start by defining a helper function which creates an LDA model. It takes <code>k</code> as argument which is the number of topics. It then adds a coherence measure to the model and returns a coherence score.</p>
<div class="sourceCode" id="cb247"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb247-1"><a href="lda-topic-modelling.html#cb247-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_coherence_values(k):</span>
<span id="cb247-2"><a href="lda-topic-modelling.html#cb247-2" aria-hidden="true" tabindex="-1"></a>    lda_model <span class="op">=</span> gensim.models.ldamodel.LdaModel(corpus<span class="op">=</span>corpus,</span>
<span id="cb247-3"><a href="lda-topic-modelling.html#cb247-3" aria-hidden="true" tabindex="-1"></a>                                           id2word<span class="op">=</span>id2word,</span>
<span id="cb247-4"><a href="lda-topic-modelling.html#cb247-4" aria-hidden="true" tabindex="-1"></a>                                           num_topics<span class="op">=</span>k, </span>
<span id="cb247-5"><a href="lda-topic-modelling.html#cb247-5" aria-hidden="true" tabindex="-1"></a>                                           random_state<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb247-6"><a href="lda-topic-modelling.html#cb247-6" aria-hidden="true" tabindex="-1"></a>                                           chunksize<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb247-7"><a href="lda-topic-modelling.html#cb247-7" aria-hidden="true" tabindex="-1"></a>                                           passes<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb247-8"><a href="lda-topic-modelling.html#cb247-8" aria-hidden="true" tabindex="-1"></a>                                           alpha<span class="op">=</span><span class="st">&quot;auto&quot;</span>)</span>
<span id="cb247-9"><a href="lda-topic-modelling.html#cb247-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb247-10"><a href="lda-topic-modelling.html#cb247-10" aria-hidden="true" tabindex="-1"></a>    coherence_model_lda <span class="op">=</span> CoherenceModel(model<span class="op">=</span>lda_model, texts<span class="op">=</span>data_bigrams_trigrams, dictionary<span class="op">=</span>id2word, coherence<span class="op">=</span><span class="st">&#39;c_v&#39;</span>)</span>
<span id="cb247-11"><a href="lda-topic-modelling.html#cb247-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> coherence_model_lda.get_coherence()</span></code></pre></div>
<p>Now that we defined a helper function we can iterate over a range of topics, create a topic model for each and calculate a coherence score for each topic model. I used a range of 1:30 topics with a step size of 2. We save the result as a dataframe.</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb248-1"><a href="lda-topic-modelling.html#cb248-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Topics range</span></span>
<span id="cb248-2"><a href="lda-topic-modelling.html#cb248-2" aria-hidden="true" tabindex="-1"></a>min_topics <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb248-3"><a href="lda-topic-modelling.html#cb248-3" aria-hidden="true" tabindex="-1"></a>max_topics <span class="op">=</span> <span class="dv">30</span></span>
<span id="cb248-4"><a href="lda-topic-modelling.html#cb248-4" aria-hidden="true" tabindex="-1"></a>step_size <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb248-5"><a href="lda-topic-modelling.html#cb248-5" aria-hidden="true" tabindex="-1"></a>topics_range <span class="op">=</span> <span class="bu">range</span>(min_topics, max_topics, step_size)</span>
<span id="cb248-6"><a href="lda-topic-modelling.html#cb248-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb248-7"><a href="lda-topic-modelling.html#cb248-7" aria-hidden="true" tabindex="-1"></a><span class="co">#empty dataframe</span></span>
<span id="cb248-8"><a href="lda-topic-modelling.html#cb248-8" aria-hidden="true" tabindex="-1"></a>model_results <span class="op">=</span> {<span class="st">&#39;Topics&#39;</span>: [],</span>
<span id="cb248-9"><a href="lda-topic-modelling.html#cb248-9" aria-hidden="true" tabindex="-1"></a>                 <span class="st">&#39;Coherence&#39;</span>: []</span>
<span id="cb248-10"><a href="lda-topic-modelling.html#cb248-10" aria-hidden="true" tabindex="-1"></a>                }</span>
<span id="cb248-11"><a href="lda-topic-modelling.html#cb248-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb248-12"><a href="lda-topic-modelling.html#cb248-12" aria-hidden="true" tabindex="-1"></a><span class="co"># iterate through number of topics</span></span>
<span id="cb248-13"><a href="lda-topic-modelling.html#cb248-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> topics_range:</span>
<span id="cb248-14"><a href="lda-topic-modelling.html#cb248-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(k)</span>
<span id="cb248-15"><a href="lda-topic-modelling.html#cb248-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get the coherence score for the given topics</span></span>
<span id="cb248-16"><a href="lda-topic-modelling.html#cb248-16" aria-hidden="true" tabindex="-1"></a>    cv <span class="op">=</span> compute_coherence_values(k<span class="op">=</span>k)</span>
<span id="cb248-17"><a href="lda-topic-modelling.html#cb248-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save the model results</span></span>
<span id="cb248-18"><a href="lda-topic-modelling.html#cb248-18" aria-hidden="true" tabindex="-1"></a>    model_results[<span class="st">&#39;Topics&#39;</span>].append(k)</span>
<span id="cb248-19"><a href="lda-topic-modelling.html#cb248-19" aria-hidden="true" tabindex="-1"></a>    model_results[<span class="st">&#39;Coherence&#39;</span>].append(cv)</span>
<span id="cb248-20"><a href="lda-topic-modelling.html#cb248-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb248-21"><a href="lda-topic-modelling.html#cb248-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb248-22"><a href="lda-topic-modelling.html#cb248-22" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(model_results).to_csv(<span class="st">&#39;data/lda_topic_model/tuning_results_nyt.csv&#39;</span>, index<span class="op">=</span><span class="va">False</span>)    </span></code></pre></div>
<div id="selecting-number-of-topics-for-new-york-times" class="section level3" number="15.6.1">
<h3><span class="header-section-number">15.6.1</span> Selecting number of topics for New York Times</h3>
<p>We now move into R for a lil bit to make some plots. Here we load packages <code>tidyverse</code> <span class="citation">(<a href="#ref-tidyverse2019" role="doc-biblioref">Wickham et al. 2019</a>)</span>, <code>wesanderson</code> <span class="citation">(<a href="#ref-R-wesanderson" role="doc-biblioref">Ram and Wickham 2018</a>)</span> and <code>RColorBrewer</code> <span class="citation">(<a href="#ref-R-rcolorbrewer" role="doc-biblioref"><strong>R-rcolorbrewer?</strong></a>)</span>.</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="lda-topic-modelling.html#cb249-1" aria-hidden="true" tabindex="-1"></a>pacman<span class="sc">::</span><span class="fu">p_load</span>(tidyverse, wesanderson, RColorBrewer)</span></code></pre></div>
<p>Here I quickly define some color palettes with colors that i like. These palettes will be used for different plots. The same colors will be used consistently throughout the notebook.</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="lda-topic-modelling.html#cb250-1" aria-hidden="true" tabindex="-1"></a>color_palette_newspaper <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">wes_palette</span>(<span class="st">&quot;Chevalier1&quot;</span>)[<span class="dv">1</span>], <span class="fu">wes_palette</span>(<span class="st">&quot;Darjeeling2&quot;</span>)[<span class="dv">2</span>])</span></code></pre></div>
<p>Lets plot the coherence score against number of topics for New York Times.</p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="lda-topic-modelling.html#cb251-1" aria-hidden="true" tabindex="-1"></a>lda_tuning_results_NYT <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/lda_topic_model/tuning_results_NYT.csv&quot;</span>)</span>
<span id="cb251-2"><a href="lda-topic-modelling.html#cb251-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb251-3"><a href="lda-topic-modelling.html#cb251-3" aria-hidden="true" tabindex="-1"></a>lda_tuning_results_NYT <span class="sc">%&gt;%</span></span>
<span id="cb251-4"><a href="lda-topic-modelling.html#cb251-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb251-5"><a href="lda-topic-modelling.html#cb251-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x=</span>Topics, <span class="at">y=</span>Coherence) <span class="sc">+</span> </span>
<span id="cb251-6"><a href="lda-topic-modelling.html#cb251-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">color =</span> color_palette_newspaper[<span class="dv">1</span>], <span class="at">size =</span> <span class="fl">1.1</span>) <span class="sc">+</span> </span>
<span id="cb251-7"><a href="lda-topic-modelling.html#cb251-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">color =</span> color_palette_newspaper[<span class="dv">1</span>], <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb251-8"><a href="lda-topic-modelling.html#cb251-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">30</span>, <span class="at">by =</span> <span class="dv">2</span>)) <span class="sc">+</span> </span>
<span id="cb251-9"><a href="lda-topic-modelling.html#cb251-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb251-10"><a href="lda-topic-modelling.html#cb251-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Number of Topics&quot;</span>, <span class="at">y=</span><span class="st">&quot;Coherence Score&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Choosing Optimal Number of Topics for New York Times&quot;</span>) <span class="sc">+</span> </span>
<span id="cb251-11"><a href="lda-topic-modelling.html#cb251-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ylim</span>(<span class="fl">0.38</span>,<span class="fl">0.52</span>)</span></code></pre></div>
<div class="figure">
<img src="_main_files/figure-html/tuning_nyt-1.png" alt="Coherence score plotted for topic models with varying number of topics. 7 Topics are chosen for the topic model in New York Times" width="672" />
<p class="caption">
(#fig:tuning_nyt)Coherence score plotted for topic models with varying number of topics. 7 Topics are chosen for the topic model in New York Times
</p>
</div>
<p>Figure @ref(fig:tuning_nyt) outlines the coherence score for the number of topics in the topic model on articles from New York Times.
We want to pick the value in the graph where there is a breaking point. This is the point where the coherence score is highest before flattening out. In other words we want to pick the lowest number of topics where the coherence score begins to level off.
<strong>I choose to go with 7 topics for the topic model in New York Times</strong></p>
</div>
<div id="selecting-number-of-topics-for-the-guardian" class="section level3" number="15.6.2">
<h3><span class="header-section-number">15.6.2</span> Selecting number of topics for The Guardian</h3>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="lda-topic-modelling.html#cb252-1" aria-hidden="true" tabindex="-1"></a>lda_tuning_results_guardian <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/lda_topic_model/tuning_results_guardian.csv&quot;</span>)</span>
<span id="cb252-2"><a href="lda-topic-modelling.html#cb252-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb252-3"><a href="lda-topic-modelling.html#cb252-3" aria-hidden="true" tabindex="-1"></a>lda_tuning_results_guardian <span class="sc">%&gt;%</span></span>
<span id="cb252-4"><a href="lda-topic-modelling.html#cb252-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb252-5"><a href="lda-topic-modelling.html#cb252-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x=</span>Topics, <span class="at">y=</span>Coherence) <span class="sc">+</span> </span>
<span id="cb252-6"><a href="lda-topic-modelling.html#cb252-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">color =</span> color_palette_newspaper[<span class="dv">2</span>], <span class="at">size =</span> <span class="fl">1.1</span>) <span class="sc">+</span> </span>
<span id="cb252-7"><a href="lda-topic-modelling.html#cb252-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">color =</span> color_palette_newspaper[<span class="dv">2</span>], <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb252-8"><a href="lda-topic-modelling.html#cb252-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">30</span>, <span class="at">by =</span> <span class="dv">2</span>)) <span class="sc">+</span> </span>
<span id="cb252-9"><a href="lda-topic-modelling.html#cb252-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb252-10"><a href="lda-topic-modelling.html#cb252-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Number of Topics&quot;</span>, <span class="at">y=</span><span class="st">&quot;Coherence Score&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Choosing Optimal Number of Topics for The Guardian&quot;</span>) <span class="sc">+</span> </span>
<span id="cb252-11"><a href="lda-topic-modelling.html#cb252-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ylim</span>(<span class="fl">0.38</span>,<span class="fl">0.52</span>)</span></code></pre></div>
<div class="figure">
<img src="_main_files/figure-html/tuning_guardian-1.png" alt="Coherence score plotted for topic models with varying number of topics. 7 Topics are chosen for the topic model in The Guardian" width="672" />
<p class="caption">
(#fig:tuning_guardian)Coherence score plotted for topic models with varying number of topics. 7 Topics are chosen for the topic model in The Guardian
</p>
</div>
<p>Figure @ref(fig:tuning_guardian) outlines the coherence score for the number of topics in the topic model on articles from The Guardian. Using the same criteria as above we should choose the number of topics to be 13. However, this seems like too many topics and it will be difficult to compare 13 topics to the 7 topics chosen for New York Times. <strong>Therefore I choose to go with 7 topics for the topic model in The Guardian</strong></p>
</div>
</div>
<div id="building-the-topic-models" class="section level2" number="15.7">
<h2><span class="header-section-number">15.7</span> Building the topic models</h2>
<p>Here we build the topic models for New York Times and The Guardian respectively by using the number of topics designated in the previous section.</p>
<div id="new-york-times-topic-model" class="section level3" number="15.7.1">
<h3><span class="header-section-number">15.7.1</span> New York Times topic model</h3>
<p>We create the final model with the selected number of topics for NYT, changing <code>num_topics</code> to 7.</p>
<div class="sourceCode" id="cb253"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb253-1"><a href="lda-topic-modelling.html#cb253-1" aria-hidden="true" tabindex="-1"></a>lda_model_nyt <span class="op">=</span> gensim.models.ldamodel.LdaModel(corpus <span class="op">=</span> corpus,</span>
<span id="cb253-2"><a href="lda-topic-modelling.html#cb253-2" aria-hidden="true" tabindex="-1"></a>                                            id2word <span class="op">=</span> id2word,</span>
<span id="cb253-3"><a href="lda-topic-modelling.html#cb253-3" aria-hidden="true" tabindex="-1"></a>                                            num_topics <span class="op">=</span> <span class="dv">7</span>,</span>
<span id="cb253-4"><a href="lda-topic-modelling.html#cb253-4" aria-hidden="true" tabindex="-1"></a>                                            random_state <span class="op">=</span> <span class="dv">100</span>,</span>
<span id="cb253-5"><a href="lda-topic-modelling.html#cb253-5" aria-hidden="true" tabindex="-1"></a>                                            update_every <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb253-6"><a href="lda-topic-modelling.html#cb253-6" aria-hidden="true" tabindex="-1"></a>                                            chunksize <span class="op">=</span> <span class="dv">100</span>,</span>
<span id="cb253-7"><a href="lda-topic-modelling.html#cb253-7" aria-hidden="true" tabindex="-1"></a>                                            passes <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb253-8"><a href="lda-topic-modelling.html#cb253-8" aria-hidden="true" tabindex="-1"></a>                                            alpha <span class="op">=</span> <span class="st">&quot;auto&quot;</span>,</span>
<span id="cb253-9"><a href="lda-topic-modelling.html#cb253-9" aria-hidden="true" tabindex="-1"></a>                                            )</span></code></pre></div>
<p>We plot it. If you want to play around with it yourself go to the original python script.</p>
<div class="sourceCode" id="cb254"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb254-1"><a href="lda-topic-modelling.html#cb254-1" aria-hidden="true" tabindex="-1"></a>pyLDAvis.enable_notebook()</span>
<span id="cb254-2"><a href="lda-topic-modelling.html#cb254-2" aria-hidden="true" tabindex="-1"></a>vis <span class="op">=</span> pyLDAvis.gensim_models.prepare(lda_model_nyt, corpus, id2word, mds <span class="op">=</span> <span class="st">&quot;mmds&quot;</span>, R<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb254-3"><a href="lda-topic-modelling.html#cb254-3" aria-hidden="true" tabindex="-1"></a>vis</span></code></pre></div>
<div class="figure">
<img src="images/nyt_topic_model.JPG" alt="" />
<p class="caption">Topic Model for New York Times</p>
</div>
<p>In the topic model for New York Times we see that 7 topics have been created. On the left we see topics 1-7 plotted on a 2-dimensional space. The size of the circles indicate the prevalence of the topic throughout the articles. Larger means more prevalent. We see that the topics are well spread throughout the 2-dimensional space and that there is no obvious overlap between topics. On the right we see the top-words for topic number 1. I highly encourage you to run the python script yourself and play around with the vizualisation.</p>
</div>
<div id="the-guardian-topic-model" class="section level3" number="15.7.2">
<h3><span class="header-section-number">15.7.2</span> The Guardian topic model</h3>
<p>Same procedure for the guardian, changing the <code>num_topics</code> to 7.</p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="lda-topic-modelling.html#cb255-1" aria-hidden="true" tabindex="-1"></a>lda_model_guardian <span class="ot">=</span> <span class="fu">gensim.models.ldamodel.LdaModel</span>(<span class="at">corpus =</span> corpus,</span>
<span id="cb255-2"><a href="lda-topic-modelling.html#cb255-2" aria-hidden="true" tabindex="-1"></a>                                            <span class="at">id2word =</span> id2word,</span>
<span id="cb255-3"><a href="lda-topic-modelling.html#cb255-3" aria-hidden="true" tabindex="-1"></a>                                            <span class="at">num_topics =</span> <span class="dv">7</span>,</span>
<span id="cb255-4"><a href="lda-topic-modelling.html#cb255-4" aria-hidden="true" tabindex="-1"></a>                                            <span class="at">random_state =</span> <span class="dv">100</span>,</span>
<span id="cb255-5"><a href="lda-topic-modelling.html#cb255-5" aria-hidden="true" tabindex="-1"></a>                                            <span class="at">update_every =</span> <span class="dv">1</span>,</span>
<span id="cb255-6"><a href="lda-topic-modelling.html#cb255-6" aria-hidden="true" tabindex="-1"></a>                                            <span class="at">chunksize =</span> <span class="dv">100</span>,</span>
<span id="cb255-7"><a href="lda-topic-modelling.html#cb255-7" aria-hidden="true" tabindex="-1"></a>                                            <span class="at">passes =</span> <span class="dv">10</span>,</span>
<span id="cb255-8"><a href="lda-topic-modelling.html#cb255-8" aria-hidden="true" tabindex="-1"></a>                                            <span class="at">alpha =</span> <span class="st">&quot;auto&quot;</span>,</span>
<span id="cb255-9"><a href="lda-topic-modelling.html#cb255-9" aria-hidden="true" tabindex="-1"></a>                                            )</span>
<span id="cb255-10"><a href="lda-topic-modelling.html#cb255-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb255-11"><a href="lda-topic-modelling.html#cb255-11" aria-hidden="true" tabindex="-1"></a><span class="fu">pyLDAvis.enable_notebook</span>()</span>
<span id="cb255-12"><a href="lda-topic-modelling.html#cb255-12" aria-hidden="true" tabindex="-1"></a>vis <span class="ot">=</span> <span class="fu">pyLDAvis.gensim_models.prepare</span>(lda_model_guardian, corpus, id2word, <span class="at">mds =</span> <span class="st">&quot;mmds&quot;</span>, <span class="at">R=</span><span class="dv">30</span>)</span>
<span id="cb255-13"><a href="lda-topic-modelling.html#cb255-13" aria-hidden="true" tabindex="-1"></a>vis</span></code></pre></div>
<div class="figure">
<img src="images/guardian_topic_model.JPG" alt="" />
<p class="caption">Topic Model for The Guardian</p>
</div>
<p>In the topic model for The Guardian we see that 7 topics have been created. On the left we see topics 1-7 plotted on a 2-dimensional space. We see that the topics are well spread throughout the 2-dimensional space and that there is no obvious overlap between topics. On the right we see the top-words for topic number 1. I highly encourage you to run the python script yourself and play around with the vizualisation.</p>
</div>
</div>
<div id="assigning-one-topic-to-each-article" class="section level2" number="15.8">
<h2><span class="header-section-number">15.8</span> Assigning one topic to each article</h2>
<p>Remember that each article in an LDA topic model is comprised of a distribution of topics. Let me elaborate with an example.</p>
<p>The topic distribution for article x might look something like this:</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="lda-topic-modelling.html#cb256-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb256-2"><a href="lda-topic-modelling.html#cb256-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">Topic =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>),</span>
<span id="cb256-3"><a href="lda-topic-modelling.html#cb256-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">Topic_contribution =</span> <span class="fu">c</span>(<span class="fl">0.05</span>, <span class="fl">0.10</span>, <span class="fl">0.30</span>, <span class="fl">0.02</span>, <span class="fl">0.03</span>, <span class="fl">0.05</span>, <span class="fl">0.45</span>)</span>
<span id="cb256-4"><a href="lda-topic-modelling.html#cb256-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb256-5"><a href="lda-topic-modelling.html#cb256-5" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="at">caption =</span> <span class="st">&quot;Example: Topic distribution for article x&quot;</span>,</span>
<span id="cb256-6"><a href="lda-topic-modelling.html#cb256-6" aria-hidden="true" tabindex="-1"></a>               <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">&quot;Topic Number&quot;</span>, <span class="st">&quot;Topic Contribution&quot;</span>))</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-146">Table 15.1: </span>Example: Topic distribution for article x</caption>
<thead>
<tr class="header">
<th align="right">Topic Number</th>
<th align="right">Topic Contribution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.05</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">0.10</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">0.30</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">0.02</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">0.03</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">0.05</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">0.45</td>
</tr>
</tbody>
</table>
<p>We see that article x is not fit into a single topic but rather that each topic has a probability associated to it. All these probabilities add up to 1. We are going to reduce this dimensionality, such that each article is assigned to the topic which is has the highest probability of belonging to. In essence, we are throwing away the probabilistic nature of the model, but in return we get a format that is easier to handle. In this example article x would be assigned to topic number 7.</p>
<p>Now back to the real business. The code below iterates through all the articles in the dataframe and extract the probability of each topic for each article.</p>
<div class="sourceCode" id="cb257"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb257-1"><a href="lda-topic-modelling.html#cb257-1" aria-hidden="true" tabindex="-1"></a>all_topics <span class="op">=</span> []</span>
<span id="cb257-2"><a href="lda-topic-modelling.html#cb257-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb257-3"><a href="lda-topic-modelling.html#cb257-3" aria-hidden="true" tabindex="-1"></a><span class="co">#looping through all the articles in df</span></span>
<span id="cb257-4"><a href="lda-topic-modelling.html#cb257-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(df_nyt)):</span>
<span id="cb257-5"><a href="lda-topic-modelling.html#cb257-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">#getting the probability and index of each topic for given article </span></span>
<span id="cb257-6"><a href="lda-topic-modelling.html#cb257-6" aria-hidden="true" tabindex="-1"></a>    top_topics <span class="op">=</span> lda_model_nyt.get_document_topics(corpus[i], minimum_probability<span class="op">=</span><span class="fl">0.0</span>)</span>
<span id="cb257-7"><a href="lda-topic-modelling.html#cb257-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb257-8"><a href="lda-topic-modelling.html#cb257-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#checking if there was some lists that were not functioning correctly</span></span>
<span id="cb257-9"><a href="lda-topic-modelling.html#cb257-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(top_topics) <span class="op">!=</span> <span class="dv">7</span>:</span>
<span id="cb257-10"><a href="lda-topic-modelling.html#cb257-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;List of Topics is not 7 in article number &quot;</span> <span class="op">+</span> <span class="bu">str</span>(i))</span>
<span id="cb257-11"><a href="lda-topic-modelling.html#cb257-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb257-12"><a href="lda-topic-modelling.html#cb257-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#removing the index of the topic, keep only the probabilities</span></span>
<span id="cb257-13"><a href="lda-topic-modelling.html#cb257-13" aria-hidden="true" tabindex="-1"></a>    topic_vec_prop <span class="op">=</span> [top_topics[i][<span class="dv">1</span>] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">7</span>)]</span>
<span id="cb257-14"><a href="lda-topic-modelling.html#cb257-14" aria-hidden="true" tabindex="-1"></a>    all_topics.append(topic_vec_prop)</span></code></pre></div>
<p>Then, for each article we find the topic with the highest probability and we also find the probability of that topic.</p>
<div class="sourceCode" id="cb258"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb258-1"><a href="lda-topic-modelling.html#cb258-1" aria-hidden="true" tabindex="-1"></a>dominant_topic <span class="op">=</span> []</span>
<span id="cb258-2"><a href="lda-topic-modelling.html#cb258-2" aria-hidden="true" tabindex="-1"></a>topic_contribution <span class="op">=</span> []</span>
<span id="cb258-3"><a href="lda-topic-modelling.html#cb258-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb258-4"><a href="lda-topic-modelling.html#cb258-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> all_topics:</span>
<span id="cb258-5"><a href="lda-topic-modelling.html#cb258-5" aria-hidden="true" tabindex="-1"></a>    max_prop <span class="op">=</span> <span class="bu">max</span>(i)</span>
<span id="cb258-6"><a href="lda-topic-modelling.html#cb258-6" aria-hidden="true" tabindex="-1"></a>    max_index <span class="op">=</span> i.index(max_prop)</span>
<span id="cb258-7"><a href="lda-topic-modelling.html#cb258-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb258-8"><a href="lda-topic-modelling.html#cb258-8" aria-hidden="true" tabindex="-1"></a>    dominant_topic.append(max_index)</span>
<span id="cb258-9"><a href="lda-topic-modelling.html#cb258-9" aria-hidden="true" tabindex="-1"></a>    topic_contribution.append(max_prop)</span></code></pre></div>
<p>We save the dominant topic and its contribution to two new columns in the dataframe.</p>
<div class="sourceCode" id="cb259"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb259-1"><a href="lda-topic-modelling.html#cb259-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;dominant_topic&#39;</span>] <span class="op">=</span> dominant_topic</span>
<span id="cb259-2"><a href="lda-topic-modelling.html#cb259-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;topic_contribution&#39;</span>] <span class="op">=</span> topic_contribution</span></code></pre></div>
<p>And we save the dataframe with the added columns.</p>
<div class="sourceCode" id="cb260"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb260-1"><a href="lda-topic-modelling.html#cb260-1" aria-hidden="true" tabindex="-1"></a><span class="co">#splitting into three datasets</span></span>
<span id="cb260-2"><a href="lda-topic-modelling.html#cb260-2" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> df.iloc[<span class="dv">0</span>:<span class="dv">7500</span>,]</span>
<span id="cb260-3"><a href="lda-topic-modelling.html#cb260-3" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> df.iloc[<span class="dv">7501</span>:<span class="dv">15000</span>,]</span>
<span id="cb260-4"><a href="lda-topic-modelling.html#cb260-4" aria-hidden="true" tabindex="-1"></a>df3 <span class="op">=</span> df.iloc[<span class="dv">15001</span>:<span class="dv">21109</span>, ]</span>
<span id="cb260-5"><a href="lda-topic-modelling.html#cb260-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb260-6"><a href="lda-topic-modelling.html#cb260-6" aria-hidden="true" tabindex="-1"></a><span class="co">#saving to three new files</span></span>
<span id="cb260-7"><a href="lda-topic-modelling.html#cb260-7" aria-hidden="true" tabindex="-1"></a>df1.to_csv(<span class="st">&quot;data/new_york_times/NYT_clean_1.csv&quot;</span>, index <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb260-8"><a href="lda-topic-modelling.html#cb260-8" aria-hidden="true" tabindex="-1"></a>df2.to_csv(<span class="st">&quot;data/new_york_times/NYT_clean_2.csv&quot;</span>, index <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb260-9"><a href="lda-topic-modelling.html#cb260-9" aria-hidden="true" tabindex="-1"></a>df3.to_csv(<span class="st">&quot;data/new_york_times/NYT_clean_3.csv&quot;</span>, index <span class="op">=</span> <span class="va">False</span>)</span></code></pre></div>
<div id="evaluating-the-assignment-of-one-article" class="section level3" number="15.8.1">
<h3><span class="header-section-number">15.8.1</span> Evaluating the assignment of one article</h3>
<p>All right now we have assigned one topic to each article. This format is easy to handle but it throws away a lot of information from the topic model. As described in the example in section ?? some articles have clear distributions, making them belong more clearly to a single topic whereas other articles are more difficult to place inside a single topic.</p>
<p>We basically want to articles to have a clear distribution, showing a clear belonging to a single topic. We get a sense of how well the articles fit into a single topic by making two plots:</p>
<ol style="list-style-type: decimal">
<li>Plotting the distribution of <code>topic_contribution</code> which is the probability of the dominant topic.</li>
<li>Plotting the distribution of <code>topic_contribution</code> for each topic, to see if certain topics are more problematic than others.</li>
</ol>
<p>We start by loading the data for both NYT and The Guardian.</p>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="lda-topic-modelling.html#cb261-1" aria-hidden="true" tabindex="-1"></a><span class="co">#NYT</span></span>
<span id="cb261-2"><a href="lda-topic-modelling.html#cb261-2" aria-hidden="true" tabindex="-1"></a>df1 <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/new_york_times/NYT_clean_1.csv&quot;</span>)</span>
<span id="cb261-3"><a href="lda-topic-modelling.html#cb261-3" aria-hidden="true" tabindex="-1"></a>df2 <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/new_york_times/NYT_clean_2.csv&quot;</span>)</span>
<span id="cb261-4"><a href="lda-topic-modelling.html#cb261-4" aria-hidden="true" tabindex="-1"></a>df3 <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/new_york_times/NYT_clean_3.csv&quot;</span>)</span>
<span id="cb261-5"><a href="lda-topic-modelling.html#cb261-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb261-6"><a href="lda-topic-modelling.html#cb261-6" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">rbind</span>(df1, df2, df3)</span>
<span id="cb261-7"><a href="lda-topic-modelling.html#cb261-7" aria-hidden="true" tabindex="-1"></a>df_NYT <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(df) <span class="sc">%&gt;%</span> </span>
<span id="cb261-8"><a href="lda-topic-modelling.html#cb261-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(</span>
<span id="cb261-9"><a href="lda-topic-modelling.html#cb261-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">newspaper =</span> <span class="st">&quot;New York Times&quot;</span></span>
<span id="cb261-10"><a href="lda-topic-modelling.html#cb261-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb261-11"><a href="lda-topic-modelling.html#cb261-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb261-12"><a href="lda-topic-modelling.html#cb261-12" aria-hidden="true" tabindex="-1"></a><span class="co">#The Guardian</span></span>
<span id="cb261-13"><a href="lda-topic-modelling.html#cb261-13" aria-hidden="true" tabindex="-1"></a>df_guardian <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/guardian/guardian_clean.csv&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb261-14"><a href="lda-topic-modelling.html#cb261-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(</span>
<span id="cb261-15"><a href="lda-topic-modelling.html#cb261-15" aria-hidden="true" tabindex="-1"></a>        <span class="at">newspaper =</span> <span class="st">&quot;The Guardian&quot;</span></span>
<span id="cb261-16"><a href="lda-topic-modelling.html#cb261-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb261-17"><a href="lda-topic-modelling.html#cb261-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb261-18"><a href="lda-topic-modelling.html#cb261-18" aria-hidden="true" tabindex="-1"></a><span class="co">#combined</span></span>
<span id="cb261-19"><a href="lda-topic-modelling.html#cb261-19" aria-hidden="true" tabindex="-1"></a>df_all <span class="ot">&lt;-</span> <span class="fu">rbind</span>(df_NYT, df_guardian)</span>
<span id="cb261-20"><a href="lda-topic-modelling.html#cb261-20" aria-hidden="true" tabindex="-1"></a>df_all <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(df_all)</span></code></pre></div>
<p>Here we plot the distribution of <code>topic_contribution</code> for both datasets.</p>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="lda-topic-modelling.html#cb262-1" aria-hidden="true" tabindex="-1"></a>df_all <span class="sc">%&gt;%</span> </span>
<span id="cb262-2"><a href="lda-topic-modelling.html#cb262-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb262-3"><a href="lda-topic-modelling.html#cb262-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>topic_contribution, <span class="at">fill =</span> newspaper) <span class="sc">+</span> </span>
<span id="cb262-4"><a href="lda-topic-modelling.html#cb262-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb262-5"><a href="lda-topic-modelling.html#cb262-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(df_NYT<span class="sc">$</span>topic_contribution), <span class="at">color =</span> color_palette_newspaper[<span class="dv">1</span>]) <span class="sc">+</span></span>
<span id="cb262-6"><a href="lda-topic-modelling.html#cb262-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(df_guardian<span class="sc">$</span>topic_contribution), <span class="at">color =</span> color_palette_newspaper[<span class="dv">2</span>]) <span class="sc">+</span></span>
<span id="cb262-7"><a href="lda-topic-modelling.html#cb262-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb262-8"><a href="lda-topic-modelling.html#cb262-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> color_palette_newspaper, <span class="at">name =</span> <span class="st">&quot;&quot;</span>) <span class="sc">+</span> </span>
<span id="cb262-9"><a href="lda-topic-modelling.html#cb262-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>newspaper, <span class="at">nrow =</span> <span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb262-10"><a href="lda-topic-modelling.html#cb262-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;dominant topic contribution&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Distributions of Dominant Topic Contribution&quot;</span>) <span class="sc">+</span> </span>
<span id="cb262-11"><a href="lda-topic-modelling.html#cb262-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) <span class="sc">+</span> </span>
<span id="cb262-12"><a href="lda-topic-modelling.html#cb262-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">0</span>,<span class="dv">1</span>)   </span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:dominanttopiccontribution"></span>
<img src="_main_files/figure-html/dominanttopiccontribution-1.png" alt="Distributions of dominant topic contribution for New York Times and The Guardian respectively. Dominant topic contribution is the association between an article and the highest ranking topic for that article. High values indicate that the article belong more clearly to a single topic. Low values indicate the the article is more ambigious and cannot be placed so clearly within a single topic. The vertical yellow and green line show the mean of dominant topic contribution for the two newspapers respectively. " width="672" />
<p class="caption">
Figure 15.1: Distributions of dominant topic contribution for New York Times and The Guardian respectively. Dominant topic contribution is the association between an article and the highest ranking topic for that article. High values indicate that the article belong more clearly to a single topic. Low values indicate the the article is more ambigious and cannot be placed so clearly within a single topic. The vertical yellow and green line show the mean of dominant topic contribution for the two newspapers respectively.
</p>
</div>
<p>In figure <a href="lda-topic-modelling.html#fig:dominanttopiccontribution">15.1</a> we see distributions of dominant topic contribution for New York Times and The Guardian respectively. High values indicate that the article belong more clearly to a single topic. Low values indicate the the article is more ambigious and cannot be placed so clearly within a single topic. The vertical yellow and green line show the mean of dominant topic contribution for the two newspapers respectively.</p>
<p>Overall I am pretty satisfied with the results of this. We see that the mean dominant topic contribution is ~.40 which is good considering that there are 7 topics, so a completely ambigious score would be 0.14. However, we do see some values drop to about 0.17 but there are very few of these.</p>
<p>Moreover, the mean dominant topic contribution for The Guardian is <em>lower</em> compared to the mean dominant topic contribution New York Times. This means that the article in New York Times on average belong more clearly to a single topic.</p>
<p>Next up we plot the distributions of <code>topic_contribution</code> for each topic, to see if certain topics are more ambigious than others. We do this for both newspapers.</p>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="lda-topic-modelling.html#cb263-1" aria-hidden="true" tabindex="-1"></a>df_mean <span class="ot">&lt;-</span> df_all <span class="sc">%&gt;%</span> </span>
<span id="cb263-2"><a href="lda-topic-modelling.html#cb263-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(newspaper <span class="sc">==</span> <span class="st">&quot;New York Times&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb263-3"><a href="lda-topic-modelling.html#cb263-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(</span>
<span id="cb263-4"><a href="lda-topic-modelling.html#cb263-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">dominant_topic =</span> dominant_topic <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb263-5"><a href="lda-topic-modelling.html#cb263-5" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb263-6"><a href="lda-topic-modelling.html#cb263-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(dominant_topic) <span class="sc">%&gt;%</span> </span>
<span id="cb263-7"><a href="lda-topic-modelling.html#cb263-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarise</span>(<span class="at">mean_topic_contribution =</span> <span class="fu">mean</span>(topic_contribution))</span>
<span id="cb263-8"><a href="lda-topic-modelling.html#cb263-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb263-9"><a href="lda-topic-modelling.html#cb263-9" aria-hidden="true" tabindex="-1"></a>df_all_p <span class="ot">&lt;-</span> df_all <span class="sc">%&gt;%</span> </span>
<span id="cb263-10"><a href="lda-topic-modelling.html#cb263-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">dominant_topic =</span> dominant_topic <span class="sc">+</span> <span class="dv">1</span>,</span>
<span id="cb263-11"><a href="lda-topic-modelling.html#cb263-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">dominant_topic =</span> <span class="fu">as.factor</span>(dominant_topic),</span>
<span id="cb263-12"><a href="lda-topic-modelling.html#cb263-12" aria-hidden="true" tabindex="-1"></a>         <span class="at">dominant_topic_name =</span> <span class="fu">paste</span>(<span class="st">&quot;Topic&quot;</span>, <span class="fu">as.character</span>(dominant_topic)))</span>
<span id="cb263-13"><a href="lda-topic-modelling.html#cb263-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb263-14"><a href="lda-topic-modelling.html#cb263-14" aria-hidden="true" tabindex="-1"></a>df_all_p <span class="ot">&lt;-</span> df_all_p <span class="sc">%&gt;%</span> </span>
<span id="cb263-15"><a href="lda-topic-modelling.html#cb263-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">dominant_topic =</span> <span class="fu">fct_relevel</span>(dominant_topic, <span class="fu">c</span>(<span class="st">&quot;7&quot;</span>, <span class="st">&quot;4&quot;</span>, <span class="st">&quot;2&quot;</span>, <span class="st">&quot;1&quot;</span>, <span class="st">&quot;5&quot;</span>, <span class="st">&quot;3&quot;</span>, <span class="st">&quot;6&quot;</span>)))</span>
<span id="cb263-16"><a href="lda-topic-modelling.html#cb263-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb263-17"><a href="lda-topic-modelling.html#cb263-17" aria-hidden="true" tabindex="-1"></a>df_all_p <span class="sc">%&gt;%</span> </span>
<span id="cb263-18"><a href="lda-topic-modelling.html#cb263-18" aria-hidden="true" tabindex="-1"></a> <span class="fu">filter</span>(newspaper <span class="sc">==</span> <span class="st">&quot;New York Times&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb263-19"><a href="lda-topic-modelling.html#cb263-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">dominant_topic_name =</span> <span class="fu">paste</span>(<span class="st">&quot;Topic&quot;</span>, <span class="fu">as.character</span>(dominant_topic))) <span class="sc">%&gt;%</span> </span>
<span id="cb263-20"><a href="lda-topic-modelling.html#cb263-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb263-21"><a href="lda-topic-modelling.html#cb263-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>topic_contribution, <span class="at">fill =</span> dominant_topic_name) <span class="sc">+</span> </span>
<span id="cb263-22"><a href="lda-topic-modelling.html#cb263-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb263-23"><a href="lda-topic-modelling.html#cb263-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">data =</span> df_mean, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">xintercept =</span> mean_topic_contribution)) <span class="sc">+</span> </span>
<span id="cb263-24"><a href="lda-topic-modelling.html#cb263-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb263-25"><a href="lda-topic-modelling.html#cb263-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> RColorBrewer<span class="sc">::</span><span class="fu">brewer.pal</span>(<span class="dv">7</span>, <span class="st">&quot;Set2&quot;</span>), <span class="at">name =</span> <span class="st">&quot;&quot;</span>) <span class="sc">+</span> </span>
<span id="cb263-26"><a href="lda-topic-modelling.html#cb263-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>dominant_topic_name, <span class="at">nrow =</span> <span class="dv">7</span>) <span class="sc">+</span> </span>
<span id="cb263-27"><a href="lda-topic-modelling.html#cb263-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">0</span>,<span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb263-28"><a href="lda-topic-modelling.html#cb263-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;dominant topic contribution&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Distributions of Dominant Topic Contribution pr. Topic&quot;</span>, <span class="at">subtitle =</span> <span class="st">&quot;New York Times&quot;</span>) <span class="sc">+</span> </span>
<span id="cb263-29"><a href="lda-topic-modelling.html#cb263-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>) </span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-148-1.png" width="672" /></p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="lda-topic-modelling.html#cb264-1" aria-hidden="true" tabindex="-1"></a>df_mean <span class="ot">&lt;-</span> df_all <span class="sc">%&gt;%</span> </span>
<span id="cb264-2"><a href="lda-topic-modelling.html#cb264-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(newspaper <span class="sc">==</span> <span class="st">&quot;The Guardian&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb264-3"><a href="lda-topic-modelling.html#cb264-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(</span>
<span id="cb264-4"><a href="lda-topic-modelling.html#cb264-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">dominant_topic =</span> dominant_topic <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb264-5"><a href="lda-topic-modelling.html#cb264-5" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb264-6"><a href="lda-topic-modelling.html#cb264-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(dominant_topic) <span class="sc">%&gt;%</span> </span>
<span id="cb264-7"><a href="lda-topic-modelling.html#cb264-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarise</span>(<span class="at">mean_topic_contribution =</span> <span class="fu">mean</span>(topic_contribution))</span>
<span id="cb264-8"><a href="lda-topic-modelling.html#cb264-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb264-9"><a href="lda-topic-modelling.html#cb264-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb264-10"><a href="lda-topic-modelling.html#cb264-10" aria-hidden="true" tabindex="-1"></a>df_all <span class="sc">%&gt;%</span> </span>
<span id="cb264-11"><a href="lda-topic-modelling.html#cb264-11" aria-hidden="true" tabindex="-1"></a> <span class="fu">filter</span>(newspaper <span class="sc">==</span> <span class="st">&quot;The Guardian&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb264-12"><a href="lda-topic-modelling.html#cb264-12" aria-hidden="true" tabindex="-1"></a> <span class="fu">mutate</span>(</span>
<span id="cb264-13"><a href="lda-topic-modelling.html#cb264-13" aria-hidden="true" tabindex="-1"></a>        <span class="at">dominant_topic =</span> dominant_topic <span class="sc">+</span> <span class="dv">1</span>,      </span>
<span id="cb264-14"><a href="lda-topic-modelling.html#cb264-14" aria-hidden="true" tabindex="-1"></a>        <span class="at">dominant_topic_name =</span> <span class="fu">paste</span>(<span class="st">&quot;Topic&quot;</span>, <span class="fu">as.character</span>(dominant_topic))</span>
<span id="cb264-15"><a href="lda-topic-modelling.html#cb264-15" aria-hidden="true" tabindex="-1"></a>        )<span class="sc">%&gt;%</span> </span>
<span id="cb264-16"><a href="lda-topic-modelling.html#cb264-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb264-17"><a href="lda-topic-modelling.html#cb264-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>topic_contribution, <span class="at">fill =</span> dominant_topic_name) <span class="sc">+</span> </span>
<span id="cb264-18"><a href="lda-topic-modelling.html#cb264-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb264-19"><a href="lda-topic-modelling.html#cb264-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">data =</span> df_mean, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">xintercept =</span> mean_topic_contribution)) <span class="sc">+</span> </span>
<span id="cb264-20"><a href="lda-topic-modelling.html#cb264-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span> </span>
<span id="cb264-21"><a href="lda-topic-modelling.html#cb264-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> RColorBrewer<span class="sc">::</span><span class="fu">brewer.pal</span>(<span class="dv">7</span>, <span class="st">&quot;Set1&quot;</span>), <span class="at">name =</span> <span class="st">&quot;&quot;</span>) <span class="sc">+</span> </span>
<span id="cb264-22"><a href="lda-topic-modelling.html#cb264-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>dominant_topic, <span class="at">nrow =</span> <span class="dv">7</span>) <span class="sc">+</span> </span>
<span id="cb264-23"><a href="lda-topic-modelling.html#cb264-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">0</span>,<span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb264-24"><a href="lda-topic-modelling.html#cb264-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;dominant topic contribution&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Distributions of Dominant Topic Contribution pr. Topic&quot;</span>, <span class="at">subtitle =</span> <span class="st">&quot;The Guardian&quot;</span>) <span class="sc">+</span> </span>
<span id="cb264-25"><a href="lda-topic-modelling.html#cb264-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-149-1.png" width="672" /></p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-R-wesanderson" class="csl-entry">
Ram, Karthik, and Hadley Wickham. 2018. <em>Wesanderson: A Wes Anderson Palette Generator</em>. <a href="https://github.com/karthik/wesanderson">https://github.com/karthik/wesanderson</a>.
</div>
<div id="ref-tidyverse2019" class="csl-entry">
Wickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. <span>“Welcome to the <span class="nocase">tidyverse</span>.”</span> <em>Journal of Open Source Software</em> 4 (43): 1686. <a href="https://doi.org/10.21105/joss.01686">https://doi.org/10.21105/joss.01686</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="overview-3.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="topic-model-interpretation-and-vizualisation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/18_LDAtopicmodelling.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
