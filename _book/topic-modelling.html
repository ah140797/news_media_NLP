<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Topic Modelling | Taliban Project</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Topic Modelling | Taliban Project" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Topic Modelling | Taliban Project" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  

<meta name="author" content="Anders Havbro Hjulmand" />


<meta name="date" content="2021-11-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="overview-3.html"/>
<link rel="next" href="topic-model-interpretation-and-vizualisation.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.17/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/nouislider-7.0.10/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider-7.0.10/jquery.nouislider.min.js"></script>
<link href="libs/selectize-0.12.0/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize-0.12.0/selectize.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Taliban Project</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure"><i class="fa fa-check"></i>Structure</a></li>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#how-to-read-the-notebook"><i class="fa fa-check"></i><b>0.1</b> How to read the notebook</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#cross"><i class="fa fa-check"></i><b>0.2</b> Render book</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#preview-book"><i class="fa fa-check"></i><b>0.3</b> Preview book</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#this-is-where-you-add-packages"><i class="fa fa-check"></i><b>0.4</b> This is where you add packages</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#an-unnumbered-section"><i class="fa fa-check"></i>An unnumbered section</a></li>
</ul></li>
<li class="chapter" data-level="0.5" data-path="index.html"><a href="index.html#chapters-and-sub-chapters"><i class="fa fa-check"></i><b>0.5</b> Chapters and sub-chapters</a></li>
<li class="chapter" data-level="0.6" data-path="index.html"><a href="index.html#captioned-figures-and-tables"><i class="fa fa-check"></i><b>0.6</b> Captioned figures and tables</a></li>
<li class="chapter" data-level="0.7" data-path="index.html"><a href="index.html#parts"><i class="fa fa-check"></i><b>0.7</b> Parts</a></li>
<li class="chapter" data-level="0.8" data-path="index.html"><a href="index.html#footnotes"><i class="fa fa-check"></i><b>0.8</b> Footnotes</a></li>
<li class="chapter" data-level="0.9" data-path="index.html"><a href="index.html#citations"><i class="fa fa-check"></i><b>0.9</b> Citations</a></li>
<li class="chapter" data-level="0.10" data-path="index.html"><a href="index.html#tips-and-tricks"><i class="fa fa-check"></i><b>0.10</b> Tips and Tricks</a></li>
</ul></li>
<li class="part"><span><b>I New York Times</b></span></li>
<li class="chapter" data-level="1" data-path="scraping-news-articles-with-new-york-times-api.html"><a href="scraping-news-articles-with-new-york-times-api.html"><i class="fa fa-check"></i><b>1</b> Scraping News Articles with New York Times API</a></li>
<li class="chapter" data-level="2" data-path="cleaning-the-data.html"><a href="cleaning-the-data.html"><i class="fa fa-check"></i><b>2</b> Cleaning The Data</a></li>
<li class="chapter" data-level="3" data-path="scrape-bread-text-of-articles.html"><a href="scrape-bread-text-of-articles.html"><i class="fa fa-check"></i><b>3</b> Scrape bread text of articles</a>
<ul>
<li class="chapter" data-level="3.1" data-path="scrape-bread-text-of-articles.html"><a href="scrape-bread-text-of-articles.html#scraping-in-python"><i class="fa fa-check"></i><b>3.1</b> Scraping in Python</a></li>
<li class="chapter" data-level="3.2" data-path="scrape-bread-text-of-articles.html"><a href="scrape-bread-text-of-articles.html#inspecting-the-bread-text"><i class="fa fa-check"></i><b>3.2</b> Inspecting the bread text</a></li>
</ul></li>
<li class="part"><span><b>II The Guardian</b></span></li>
<li class="chapter" data-level="4" data-path="scraping-articles-form-the-guardian.html"><a href="scraping-articles-form-the-guardian.html"><i class="fa fa-check"></i><b>4</b> Scraping articles form the Guardian</a></li>
<li class="chapter" data-level="5" data-path="cleaning-articles.html"><a href="cleaning-articles.html"><i class="fa fa-check"></i><b>5</b> Cleaning articles</a></li>
<li class="chapter" data-level="6" data-path="scrape-bread-text-of-articles-1.html"><a href="scrape-bread-text-of-articles-1.html"><i class="fa fa-check"></i><b>6</b> Scrape bread text of articles</a>
<ul>
<li class="chapter" data-level="6.1" data-path="scrape-bread-text-of-articles-1.html"><a href="scrape-bread-text-of-articles-1.html#scraping-in-python-1"><i class="fa fa-check"></i><b>6.1</b> Scraping in Python</a></li>
<li class="chapter" data-level="6.2" data-path="scrape-bread-text-of-articles-1.html"><a href="scrape-bread-text-of-articles-1.html#inspecting-the-bread-text-1"><i class="fa fa-check"></i><b>6.2</b> Inspecting the bread text</a></li>
</ul></li>
<li class="part"><span><b>III Preprocess breadtext</b></span></li>
<li class="chapter" data-level="7" data-path="preprocess-breadtext-for-both-datasets.html"><a href="preprocess-breadtext-for-both-datasets.html"><i class="fa fa-check"></i><b>7</b> Preprocess Breadtext for both Datasets</a></li>
<li class="part"><span><b>IV Named Entity recognition (NER)</b></span></li>
<li class="chapter" data-level="" data-path="overview-1.html"><a href="overview-1.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="overview-1.html"><a href="overview-1.html#structure-1"><i class="fa fa-check"></i>Structure</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="extracting-ners.html"><a href="extracting-ners.html"><i class="fa fa-check"></i><b>8</b> Extracting NER’s</a></li>
<li class="chapter" data-level="9" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html"><i class="fa fa-check"></i><b>9</b> GPE vizualisations</a>
<ul>
<li class="chapter" data-level="9.1" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#preparing-the-data"><i class="fa fa-check"></i><b>9.1</b> Preparing the data</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#renaming-countries"><i class="fa fa-check"></i><b>9.1.1</b> Renaming Countries</a></li>
<li class="chapter" data-level="9.1.2" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#every-country-gets-a-row-for-every-date"><i class="fa fa-check"></i><b>9.1.2</b> Every country gets a row for every date</a></li>
<li class="chapter" data-level="9.1.3" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#making-a-unique-dataset-for-plotly-and-shiny-respectively"><i class="fa fa-check"></i><b>9.1.3</b> Making a unique dataset for Plotly and Shiny respectively</a></li>
<li class="chapter" data-level="9.1.4" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#making-a-penalized-count"><i class="fa fa-check"></i><b>9.1.4</b> Making a penalized count</a></li>
<li class="chapter" data-level="9.1.5" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#setting-up-the-binsize"><i class="fa fa-check"></i><b>9.1.5</b> Setting up the binsize</a></li>
<li class="chapter" data-level="9.1.6" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#fixing-the-legend-scales-to-absolute-values."><i class="fa fa-check"></i><b>9.1.6</b> Fixing the legend scales to absolute values.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#interactive-maps-using-plotly"><i class="fa fa-check"></i><b>9.2</b> Interactive maps using Plotly</a></li>
<li class="chapter" data-level="9.3" data-path="gpe-vizualisations.html"><a href="gpe-vizualisations.html#shiny-app"><i class="fa fa-check"></i><b>9.3</b> Shiny App</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="vizualising-key-persons.html"><a href="vizualising-key-persons.html"><i class="fa fa-check"></i><b>10</b> Vizualising Key persons</a></li>
<li class="part"><span><b>V Sentiment Analysis</b></span></li>
<li class="chapter" data-level="" data-path="overview-2.html"><a href="overview-2.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="11" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html"><i class="fa fa-check"></i><b>11</b> Sentiment Analysis</a></li>
<li class="chapter" data-level="12" data-path="sentiment-vizualisations.html"><a href="sentiment-vizualisations.html"><i class="fa fa-check"></i><b>12</b> Sentiment Vizualisations</a></li>
<li class="part"><span><b>VI LDA Topic Modelling</b></span></li>
<li class="chapter" data-level="" data-path="overview-3.html"><a href="overview-3.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="13" data-path="topic-modelling.html"><a href="topic-modelling.html"><i class="fa fa-check"></i><b>13</b> Topic Modelling</a>
<ul>
<li class="chapter" data-level="13.1" data-path="topic-modelling.html"><a href="topic-modelling.html#bigrams-and-trigrams"><i class="fa fa-check"></i><b>13.1</b> Bigrams and Trigrams</a></li>
<li class="chapter" data-level="13.2" data-path="topic-modelling.html"><a href="topic-modelling.html#removing-frequently-occuring-words"><i class="fa fa-check"></i><b>13.2</b> Removing frequently occuring words</a></li>
<li class="chapter" data-level="13.3" data-path="topic-modelling.html"><a href="topic-modelling.html#creating-basic-lda-topic-model"><i class="fa fa-check"></i><b>13.3</b> Creating Basic LDA Topic Model</a></li>
<li class="chapter" data-level="13.4" data-path="topic-modelling.html"><a href="topic-modelling.html#selecting-the-number-of-topics"><i class="fa fa-check"></i><b>13.4</b> Selecting the number of topics</a></li>
<li class="chapter" data-level="13.5" data-path="topic-modelling.html"><a href="topic-modelling.html#creating-final-model"><i class="fa fa-check"></i><b>13.5</b> Creating final model</a></li>
<li class="chapter" data-level="13.6" data-path="topic-modelling.html"><a href="topic-modelling.html#assigning-one-topic-to-each-article"><i class="fa fa-check"></i><b>13.6</b> Assigning one topic to each article</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="topic-model-interpretation-and-vizualisation.html"><a href="topic-model-interpretation-and-vizualisation.html"><i class="fa fa-check"></i><b>14</b> Topic Model Interpretation and Vizualisation</a></li>
<li class="part"><span><b>VII All Results and Vizualisations</b></span></li>
<li class="chapter" data-level="15" data-path="all-results-and-vizualisation.html"><a href="all-results-and-vizualisation.html"><i class="fa fa-check"></i><b>15</b> All Results and Vizualisation</a></li>
<li class="part"><span><b>VIII Gender Dataset for further analysis</b></span></li>
<li class="chapter" data-level="16" data-path="gender-dataset-for-further-analysis.html"><a href="gender-dataset-for-further-analysis.html"><i class="fa fa-check"></i><b>16</b> Gender Dataset for further analysis</a>
<ul>
<li class="chapter" data-level="16.1" data-path="gender-dataset-for-further-analysis.html"><a href="gender-dataset-for-further-analysis.html#dataset-with-authors"><i class="fa fa-check"></i><b>16.1</b> Dataset with authors</a></li>
<li class="chapter" data-level="16.2" data-path="gender-dataset-for-further-analysis.html"><a href="gender-dataset-for-further-analysis.html#comparing-the-datasets"><i class="fa fa-check"></i><b>16.2</b> Comparing the datasets</a></li>
<li class="chapter" data-level="16.3" data-path="gender-dataset-for-further-analysis.html"><a href="gender-dataset-for-further-analysis.html#adding-gender-information-to-nyt_aut"><i class="fa fa-check"></i><b>16.3</b> Adding gender information to <code>NYT_aut</code></a></li>
</ul></li>
<li class="part"><span><b>IX References</b></span></li>
<li class="chapter" data-level="17" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>17</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">See Github Repo</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Taliban Project</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="topic-modelling" class="section level1" number="13">
<h1><span class="header-section-number">Chapter 13</span> Topic Modelling</h1>
<style>
div.green { background-color:#93c47d; border-radius: 5px; padding: 20px;}
</style>
<div class="green">
<p>This chapter is written in Python. To see the original file go to the folder python_scripts/.</p>
</div>
<style>
div.blue { background-color:#76a5af; border-radius: 5px; padding: 20px;}
</style>
<div class="blue">
<p>All the code in the chapter is run on both df_NYT and df_guardian but some of the code is only shown for df_nyt.</p>
</div>
<p>Lets get to the code. We load a bunch of packages and data. Importantly, we will use a new library called <code>gensim</code> which is used for topic modelling.</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb104-1"><a href="topic-modelling.html#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb104-2"><a href="topic-modelling.html#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb104-3"><a href="topic-modelling.html#cb104-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> glob</span>
<span id="cb104-4"><a href="topic-modelling.html#cb104-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-5"><a href="topic-modelling.html#cb104-5" aria-hidden="true" tabindex="-1"></a><span class="co">#Gensim</span></span>
<span id="cb104-6"><a href="topic-modelling.html#cb104-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim</span>
<span id="cb104-7"><a href="topic-modelling.html#cb104-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim.corpora <span class="im">as</span> corpora</span>
<span id="cb104-8"><a href="topic-modelling.html#cb104-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.utils <span class="im">import</span> simple_preprocess</span>
<span id="cb104-9"><a href="topic-modelling.html#cb104-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> CoherenceModel</span>
<span id="cb104-10"><a href="topic-modelling.html#cb104-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> TfidfModel</span>
<span id="cb104-11"><a href="topic-modelling.html#cb104-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> CoherenceModel</span>
<span id="cb104-12"><a href="topic-modelling.html#cb104-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-13"><a href="topic-modelling.html#cb104-13" aria-hidden="true" tabindex="-1"></a><span class="co">#spacy</span></span>
<span id="cb104-14"><a href="topic-modelling.html#cb104-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb104-15"><a href="topic-modelling.html#cb104-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-16"><a href="topic-modelling.html#cb104-16" aria-hidden="true" tabindex="-1"></a><span class="co">#vis</span></span>
<span id="cb104-17"><a href="topic-modelling.html#cb104-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyLDAvis</span>
<span id="cb104-18"><a href="topic-modelling.html#cb104-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyLDAvis.gensim_models</span>
<span id="cb104-19"><a href="topic-modelling.html#cb104-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-20"><a href="topic-modelling.html#cb104-20" aria-hidden="true" tabindex="-1"></a><span class="co">#data</span></span>
<span id="cb104-21"><a href="topic-modelling.html#cb104-21" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&quot;data/data_clean_full.csv&quot;</span>)</span></code></pre></div>
<p>Then we make a helper function that break down the articles by individual words and apply a function called <code>simple_preprocess</code> from <code>gensim</code>.</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb105-1"><a href="topic-modelling.html#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gen_words(texts):</span>
<span id="cb105-2"><a href="topic-modelling.html#cb105-2" aria-hidden="true" tabindex="-1"></a>    final <span class="op">=</span> []</span>
<span id="cb105-3"><a href="topic-modelling.html#cb105-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> text <span class="kw">in</span> texts:</span>
<span id="cb105-4"><a href="topic-modelling.html#cb105-4" aria-hidden="true" tabindex="-1"></a>        new <span class="op">=</span> gensim.utils.simple_preprocess(text)</span>
<span id="cb105-5"><a href="topic-modelling.html#cb105-5" aria-hidden="true" tabindex="-1"></a>        final.append(new)</span>
<span id="cb105-6"><a href="topic-modelling.html#cb105-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (final)</span></code></pre></div>
<div id="bigrams-and-trigrams" class="section level2" number="13.1">
<h2><span class="header-section-number">13.1</span> Bigrams and Trigrams</h2>
<p>We use the function on the articles from the dataset, to generate a list of all the articles broken down into words called <code>data_words</code>.</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="topic-modelling.html#cb106-1" aria-hidden="true" tabindex="-1"></a>data_words <span class="op">=</span> gen_words(df[<span class="st">&quot;articles_clean&quot;</span>])</span></code></pre></div>
<p>Next up we make something called <em>bigrams</em> and <em>trigrams</em>. Bigrams are 2 consecutive words in a sentence and trigrams are 3 consecutive words in a sentence. Now, not all bigrams and trigrams are relevant. We only want to pickup those that occur a substantial number of times. Some relevant bigrams could be <em>facebook page</em> or <em>valar margulis</em>. Some relevant trigrams could be …….
We pick up bigrams and trigrams so that the topic model can use them.</p>
<p>Needs more explanation here……</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb107-1"><a href="topic-modelling.html#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co">#BIGRAMS AND TRIGRAMS. You can play around with mon_count and threshold to be more or less sensitive to bigram detection.</span></span>
<span id="cb107-2"><a href="topic-modelling.html#cb107-2" aria-hidden="true" tabindex="-1"></a>bigram_phrases <span class="op">=</span> gensim.models.Phrases(data_words, min_count<span class="op">=</span><span class="dv">5</span>, threshold<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb107-3"><a href="topic-modelling.html#cb107-3" aria-hidden="true" tabindex="-1"></a>trigram_phrases <span class="op">=</span> gensim.models.Phrases(bigram_phrases[data_words], threshold<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb107-4"><a href="topic-modelling.html#cb107-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-5"><a href="topic-modelling.html#cb107-5" aria-hidden="true" tabindex="-1"></a>bigram <span class="op">=</span> gensim.models.phrases.Phraser(bigram_phrases)</span>
<span id="cb107-6"><a href="topic-modelling.html#cb107-6" aria-hidden="true" tabindex="-1"></a>trigram <span class="op">=</span> gensim.models.phrases.Phraser(trigram_phrases)</span>
<span id="cb107-7"><a href="topic-modelling.html#cb107-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-8"><a href="topic-modelling.html#cb107-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_bigrams(texts):</span>
<span id="cb107-9"><a href="topic-modelling.html#cb107-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>([bigram[doc] <span class="cf">for</span> doc <span class="kw">in</span> texts])</span>
<span id="cb107-10"><a href="topic-modelling.html#cb107-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-11"><a href="topic-modelling.html#cb107-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_trigrams(texts):</span>
<span id="cb107-12"><a href="topic-modelling.html#cb107-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ([trigram[bigram[doc]] <span class="cf">for</span> doc <span class="kw">in</span> texts])</span>
<span id="cb107-13"><a href="topic-modelling.html#cb107-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-14"><a href="topic-modelling.html#cb107-14" aria-hidden="true" tabindex="-1"></a>data_bigrams <span class="op">=</span> make_bigrams(data_words)</span>
<span id="cb107-15"><a href="topic-modelling.html#cb107-15" aria-hidden="true" tabindex="-1"></a>data_bigrams_trigrams <span class="op">=</span> make_trigrams(data_bigrams)</span></code></pre></div>
<p>Now lets see if some bigrams and trigrams has been picked up.</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="topic-modelling.html#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_words[<span class="dv">0</span>])</span>
<span id="cb108-2"><a href="topic-modelling.html#cb108-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (data_bigrams_trigrams[<span class="dv">0</span>])</span></code></pre></div>
</div>
<div id="removing-frequently-occuring-words" class="section level2" number="13.2">
<h2><span class="header-section-number">13.2</span> Removing frequently occuring words</h2>
<p>There is still one adjustment we have to make before we actually get to making the topic model. We are going to remove frequently occurring words such as <em>say</em>. The result of this removal is that our topics will be more distinct, i.e. there will be less overlap between topics.</p>
<p>Needs commenting…………</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb109-1"><a href="topic-modelling.html#cb109-1" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> data_bigrams_trigrams</span>
<span id="cb109-2"><a href="topic-modelling.html#cb109-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-3"><a href="topic-modelling.html#cb109-3" aria-hidden="true" tabindex="-1"></a>id2word <span class="op">=</span> corpora.Dictionary(texts)</span>
<span id="cb109-4"><a href="topic-modelling.html#cb109-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-5"><a href="topic-modelling.html#cb109-5" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> [id2word.doc2bow(text) <span class="cf">for</span> text <span class="kw">in</span> texts]</span>
<span id="cb109-6"><a href="topic-modelling.html#cb109-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(corpus[<span class="dv">0</span>])</span>
<span id="cb109-7"><a href="topic-modelling.html#cb109-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-8"><a href="topic-modelling.html#cb109-8" aria-hidden="true" tabindex="-1"></a><span class="co">#dont know what this is</span></span>
<span id="cb109-9"><a href="topic-modelling.html#cb109-9" aria-hidden="true" tabindex="-1"></a>tfidf <span class="op">=</span> TfidfModel(corpus, id2word<span class="op">=</span>id2word)</span>
<span id="cb109-10"><a href="topic-modelling.html#cb109-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-11"><a href="topic-modelling.html#cb109-11" aria-hidden="true" tabindex="-1"></a>low_value <span class="op">=</span> <span class="fl">0.03</span></span>
<span id="cb109-12"><a href="topic-modelling.html#cb109-12" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> []</span>
<span id="cb109-13"><a href="topic-modelling.html#cb109-13" aria-hidden="true" tabindex="-1"></a>words_missing_in_tfidf <span class="op">=</span> []</span>
<span id="cb109-14"><a href="topic-modelling.html#cb109-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(corpus)):</span>
<span id="cb109-15"><a href="topic-modelling.html#cb109-15" aria-hidden="true" tabindex="-1"></a>    bow <span class="op">=</span> corpus[i]</span>
<span id="cb109-16"><a href="topic-modelling.html#cb109-16" aria-hidden="true" tabindex="-1"></a>    low_value_words <span class="op">=</span> [] <span class="co">#reinitialize to be safe. You can skip this.</span></span>
<span id="cb109-17"><a href="topic-modelling.html#cb109-17" aria-hidden="true" tabindex="-1"></a>    tfidf_ids <span class="op">=</span> [<span class="bu">id</span> <span class="cf">for</span> <span class="bu">id</span>, value <span class="kw">in</span> tfidf[bow]]</span>
<span id="cb109-18"><a href="topic-modelling.html#cb109-18" aria-hidden="true" tabindex="-1"></a>    bow_ids <span class="op">=</span> [<span class="bu">id</span> <span class="cf">for</span> <span class="bu">id</span>, value <span class="kw">in</span> bow]</span>
<span id="cb109-19"><a href="topic-modelling.html#cb109-19" aria-hidden="true" tabindex="-1"></a>    low_value_words <span class="op">=</span> [<span class="bu">id</span> <span class="cf">for</span> <span class="bu">id</span>, value <span class="kw">in</span> tfidf[bow] <span class="cf">if</span> value <span class="op">&lt;</span> low_value]</span>
<span id="cb109-20"><a href="topic-modelling.html#cb109-20" aria-hidden="true" tabindex="-1"></a>    drops <span class="op">=</span> low_value_words<span class="op">+</span>words_missing_in_tfidf</span>
<span id="cb109-21"><a href="topic-modelling.html#cb109-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> item <span class="kw">in</span> drops:</span>
<span id="cb109-22"><a href="topic-modelling.html#cb109-22" aria-hidden="true" tabindex="-1"></a>        words.append(id2word[item])</span>
<span id="cb109-23"><a href="topic-modelling.html#cb109-23" aria-hidden="true" tabindex="-1"></a>    words_missing_in_tfidf <span class="op">=</span> [<span class="bu">id</span> <span class="cf">for</span> <span class="bu">id</span> <span class="kw">in</span> bow_ids <span class="cf">if</span> <span class="bu">id</span> <span class="kw">not</span> <span class="kw">in</span> tfidf_ids] <span class="co"># The words with tf-idf score 0 will be missing</span></span>
<span id="cb109-24"><a href="topic-modelling.html#cb109-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-25"><a href="topic-modelling.html#cb109-25" aria-hidden="true" tabindex="-1"></a>    new_bow <span class="op">=</span> [b <span class="cf">for</span> b <span class="kw">in</span> bow <span class="cf">if</span> b[<span class="dv">0</span>] <span class="kw">not</span> <span class="kw">in</span> low_value_words <span class="kw">and</span> b[<span class="dv">0</span>] <span class="kw">not</span> <span class="kw">in</span> words_missing_in_tfidf]</span>
<span id="cb109-26"><a href="topic-modelling.html#cb109-26" aria-hidden="true" tabindex="-1"></a>    corpus[i] <span class="op">=</span> new_bow</span></code></pre></div>
<p>So now our texts contain bigrams and trigrams and frequently occuring words have been removed. Now to the fun part.</p>
</div>
<div id="creating-basic-lda-topic-model" class="section level2" number="13.3">
<h2><span class="header-section-number">13.3</span> Creating Basic LDA Topic Model</h2>
<p>Now we can finally create the LDA topic model using <code>gensim</code>. We can adjust many hyperparameters such as <code>random_state</code> and <code>alpha</code> to adjust the model to our needs. We can also choose the number of topics in <code>num_topics</code> which is really important.</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb110-1"><a href="topic-modelling.html#cb110-1" aria-hidden="true" tabindex="-1"></a>lda_model <span class="op">=</span> gensim.models.ldamodel.LdaModel(corpus <span class="op">=</span> corpus,</span>
<span id="cb110-2"><a href="topic-modelling.html#cb110-2" aria-hidden="true" tabindex="-1"></a>                                            id2word <span class="op">=</span> id2word,</span>
<span id="cb110-3"><a href="topic-modelling.html#cb110-3" aria-hidden="true" tabindex="-1"></a>                                            num_topics <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb110-4"><a href="topic-modelling.html#cb110-4" aria-hidden="true" tabindex="-1"></a>                                            random_state <span class="op">=</span> <span class="dv">100</span>,</span>
<span id="cb110-5"><a href="topic-modelling.html#cb110-5" aria-hidden="true" tabindex="-1"></a>                                            update_every <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb110-6"><a href="topic-modelling.html#cb110-6" aria-hidden="true" tabindex="-1"></a>                                            chunksize <span class="op">=</span> <span class="dv">100</span>,</span>
<span id="cb110-7"><a href="topic-modelling.html#cb110-7" aria-hidden="true" tabindex="-1"></a>                                            passes <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb110-8"><a href="topic-modelling.html#cb110-8" aria-hidden="true" tabindex="-1"></a>                                            alpha <span class="op">=</span> <span class="st">&quot;auto&quot;</span>,</span>
<span id="cb110-9"><a href="topic-modelling.html#cb110-9" aria-hidden="true" tabindex="-1"></a>                                            )</span></code></pre></div>
<p>Now we can vizualise the model. If you want to play around with it yourself go to the original python script.</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb111-1"><a href="topic-modelling.html#cb111-1" aria-hidden="true" tabindex="-1"></a>pyLDAvis.enable_notebook()</span>
<span id="cb111-2"><a href="topic-modelling.html#cb111-2" aria-hidden="true" tabindex="-1"></a>vis <span class="op">=</span> pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds <span class="op">=</span> <span class="st">&quot;mmds&quot;</span>, R<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb111-3"><a href="topic-modelling.html#cb111-3" aria-hidden="true" tabindex="-1"></a>vis</span></code></pre></div>
<p>Show pictures here.</p>
</div>
<div id="selecting-the-number-of-topics" class="section level2" number="13.4">
<h2><span class="header-section-number">13.4</span> Selecting the number of topics</h2>
<p>There are many ways of evaluating an LDA topic model to see if it performs as we intend it to. Likewise there are many hyperparameters that can evaluated and tuned accordingly such as <em>alpha</em> and <em>beta</em>. Here i will evaluate and choose the number of topics using something called a coherence score. There are many coherence measures, here I use one called <code>C_v</code>.</p>
<p>In the next section of code I compute the coherence score for topic models with a varying number of topics to see which number of topics is the optimal.</p>
<p>I start by defining a helper function which creates an LDA model. It takes <code>k</code> as argument which is the number of topics. It then adds a coherence measure to the model and returns a coherence score.</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb112-1"><a href="topic-modelling.html#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_coherence_values(k):</span>
<span id="cb112-2"><a href="topic-modelling.html#cb112-2" aria-hidden="true" tabindex="-1"></a>    lda_model <span class="op">=</span> gensim.models.ldamodel.LdaModel(corpus<span class="op">=</span>corpus,</span>
<span id="cb112-3"><a href="topic-modelling.html#cb112-3" aria-hidden="true" tabindex="-1"></a>                                           id2word<span class="op">=</span>id2word,</span>
<span id="cb112-4"><a href="topic-modelling.html#cb112-4" aria-hidden="true" tabindex="-1"></a>                                           num_topics<span class="op">=</span>k, </span>
<span id="cb112-5"><a href="topic-modelling.html#cb112-5" aria-hidden="true" tabindex="-1"></a>                                           random_state<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb112-6"><a href="topic-modelling.html#cb112-6" aria-hidden="true" tabindex="-1"></a>                                           chunksize<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb112-7"><a href="topic-modelling.html#cb112-7" aria-hidden="true" tabindex="-1"></a>                                           passes<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb112-8"><a href="topic-modelling.html#cb112-8" aria-hidden="true" tabindex="-1"></a>                                           alpha<span class="op">=</span><span class="st">&quot;auto&quot;</span>)</span>
<span id="cb112-9"><a href="topic-modelling.html#cb112-9" aria-hidden="true" tabindex="-1"></a>                                           </span>
<span id="cb112-10"><a href="topic-modelling.html#cb112-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#adding coherence score</span></span>
<span id="cb112-11"><a href="topic-modelling.html#cb112-11" aria-hidden="true" tabindex="-1"></a>    coherence_model_lda <span class="op">=</span> CoherenceModel(model<span class="op">=</span>lda_model, texts<span class="op">=</span>data_bigrams_trigrams,            </span>
<span id="cb112-12"><a href="topic-modelling.html#cb112-12" aria-hidden="true" tabindex="-1"></a>    dictionary<span class="op">=</span>id2word, coherence<span class="op">=</span><span class="st">&#39;c_v&#39;</span>)</span>
<span id="cb112-13"><a href="topic-modelling.html#cb112-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> coherence_model_lda.get_coherence()</span></code></pre></div>
<p>Now that we defined a helper function we can iterate over a range of topics topics and calculate a coherence score for each topic model. I used a range of 1:30 topics. We save the result as a dataframe.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb113-1"><a href="topic-modelling.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Topics range</span></span>
<span id="cb113-2"><a href="topic-modelling.html#cb113-2" aria-hidden="true" tabindex="-1"></a>min_topics <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb113-3"><a href="topic-modelling.html#cb113-3" aria-hidden="true" tabindex="-1"></a>max_topics <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb113-4"><a href="topic-modelling.html#cb113-4" aria-hidden="true" tabindex="-1"></a>step_size <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb113-5"><a href="topic-modelling.html#cb113-5" aria-hidden="true" tabindex="-1"></a>topics_range <span class="op">=</span> <span class="bu">range</span>(min_topics, max_topics, step_size)</span>
<span id="cb113-6"><a href="topic-modelling.html#cb113-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-7"><a href="topic-modelling.html#cb113-7" aria-hidden="true" tabindex="-1"></a><span class="co">#empty dataframe</span></span>
<span id="cb113-8"><a href="topic-modelling.html#cb113-8" aria-hidden="true" tabindex="-1"></a>model_results <span class="op">=</span> {<span class="st">&#39;Topics&#39;</span>: [],</span>
<span id="cb113-9"><a href="topic-modelling.html#cb113-9" aria-hidden="true" tabindex="-1"></a>                 <span class="st">&#39;Coherence&#39;</span>: []</span>
<span id="cb113-10"><a href="topic-modelling.html#cb113-10" aria-hidden="true" tabindex="-1"></a>                }</span>
<span id="cb113-11"><a href="topic-modelling.html#cb113-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-12"><a href="topic-modelling.html#cb113-12" aria-hidden="true" tabindex="-1"></a><span class="co"># iterate through number of topics</span></span>
<span id="cb113-13"><a href="topic-modelling.html#cb113-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> topics_range:</span>
<span id="cb113-14"><a href="topic-modelling.html#cb113-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># get the coherence score for the given topics</span></span>
<span id="cb113-15"><a href="topic-modelling.html#cb113-15" aria-hidden="true" tabindex="-1"></a>    cv <span class="op">=</span> compute_coherence_values(k<span class="op">=</span>k)</span>
<span id="cb113-16"><a href="topic-modelling.html#cb113-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Save the model results</span></span>
<span id="cb113-17"><a href="topic-modelling.html#cb113-17" aria-hidden="true" tabindex="-1"></a>    model_results[<span class="st">&#39;Topics&#39;</span>].append(k)</span>
<span id="cb113-18"><a href="topic-modelling.html#cb113-18" aria-hidden="true" tabindex="-1"></a>    model_results[<span class="st">&#39;Coherence&#39;</span>].append(cv)</span>
<span id="cb113-19"><a href="topic-modelling.html#cb113-19" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb113-20"><a href="topic-modelling.html#cb113-20" aria-hidden="true" tabindex="-1"></a>    pd.DataFrame(model_results).to_csv(<span class="st">&#39;lda_tuning_results.csv&#39;</span>, index<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
<p>Lets open up the dataframe in R and do some vizualisation.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="topic-modelling.html#cb114-1" aria-hidden="true" tabindex="-1"></a>lda_tuning_results <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;lda_tuning_results.csv&quot;</span>)</span></code></pre></div>
</div>
<div id="creating-final-model" class="section level2" number="13.5">
<h2><span class="header-section-number">13.5</span> Creating final model</h2>
<p>We then create the final model with the selected number of topics.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb115-1"><a href="topic-modelling.html#cb115-1" aria-hidden="true" tabindex="-1"></a>lda_model <span class="op">=</span> gensim.models.ldamodel.LdaModel(corpus <span class="op">=</span> corpus,</span>
<span id="cb115-2"><a href="topic-modelling.html#cb115-2" aria-hidden="true" tabindex="-1"></a>                                            id2word <span class="op">=</span> id2word,</span>
<span id="cb115-3"><a href="topic-modelling.html#cb115-3" aria-hidden="true" tabindex="-1"></a>                                            num_topics <span class="op">=</span> ??,</span>
<span id="cb115-4"><a href="topic-modelling.html#cb115-4" aria-hidden="true" tabindex="-1"></a>                                            random_state <span class="op">=</span> <span class="dv">100</span>,</span>
<span id="cb115-5"><a href="topic-modelling.html#cb115-5" aria-hidden="true" tabindex="-1"></a>                                            update_every <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb115-6"><a href="topic-modelling.html#cb115-6" aria-hidden="true" tabindex="-1"></a>                                            chunksize <span class="op">=</span> <span class="dv">100</span>,</span>
<span id="cb115-7"><a href="topic-modelling.html#cb115-7" aria-hidden="true" tabindex="-1"></a>                                            passes <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb115-8"><a href="topic-modelling.html#cb115-8" aria-hidden="true" tabindex="-1"></a>                                            alpha <span class="op">=</span> <span class="st">&quot;auto&quot;</span>,</span>
<span id="cb115-9"><a href="topic-modelling.html#cb115-9" aria-hidden="true" tabindex="-1"></a>                                            )</span></code></pre></div>
</div>
<div id="assigning-one-topic-to-each-article" class="section level2" number="13.6">
<h2><span class="header-section-number">13.6</span> Assigning one topic to each article</h2>
<p>Finally we assign <em>one</em> topic to each article. In the current model, each article is assigned a probability for each topic. So article number 1 has the probabilities [Insert some code].</p>
<p>We are going to reduce this dimensionality, such that each article is assigned to the topic which is has the highest probability of belonging to. In essence, we are throwing away the probabilistic nature of the model, but in return we get a format that is easier to handle.</p>
<p>The code below iterates through all the articles in the dataframe and extract the probability of each topic for each article.</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb116-1"><a href="topic-modelling.html#cb116-1" aria-hidden="true" tabindex="-1"></a>new <span class="op">=</span> []</span>
<span id="cb116-2"><a href="topic-modelling.html#cb116-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-3"><a href="topic-modelling.html#cb116-3" aria-hidden="true" tabindex="-1"></a><span class="co">#looping through all the articles in df</span></span>
<span id="cb116-4"><a href="topic-modelling.html#cb116-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(df)):</span>
<span id="cb116-5"><a href="topic-modelling.html#cb116-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">#getting the probability of each topic </span></span>
<span id="cb116-6"><a href="topic-modelling.html#cb116-6" aria-hidden="true" tabindex="-1"></a>    top_topics <span class="op">=</span> lda_model.get_document_topics(corpus[i], minimum_probability<span class="op">=</span><span class="fl">0.0</span>)</span>
<span id="cb116-7"><a href="topic-modelling.html#cb116-7" aria-hidden="true" tabindex="-1"></a>    topic_vec_prop <span class="op">=</span> [top_topics[i][<span class="dv">1</span>] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>)]</span>
<span id="cb116-8"><a href="topic-modelling.html#cb116-8" aria-hidden="true" tabindex="-1"></a>    new.append(topic_vec_prop)</span></code></pre></div>
<p>Then, for each article we find the topic with the highest probability.</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb117-1"><a href="topic-modelling.html#cb117-1" aria-hidden="true" tabindex="-1"></a>yeye <span class="op">=</span> []</span>
<span id="cb117-2"><a href="topic-modelling.html#cb117-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> new:</span>
<span id="cb117-3"><a href="topic-modelling.html#cb117-3" aria-hidden="true" tabindex="-1"></a>    max_prop <span class="op">=</span> <span class="bu">max</span>(i)</span>
<span id="cb117-4"><a href="topic-modelling.html#cb117-4" aria-hidden="true" tabindex="-1"></a>    max_index <span class="op">=</span> i.index(max_prop)</span>
<span id="cb117-5"><a href="topic-modelling.html#cb117-5" aria-hidden="true" tabindex="-1"></a>    yeye.append(max_index)</span></code></pre></div>
<p>Lastly, we save the topic to a new column in the dataframe.</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb118-1"><a href="topic-modelling.html#cb118-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;topic&#39;</span>] <span class="op">=</span> yeye</span></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="overview-3.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="topic-model-interpretation-and-vizualisation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/16_LDAtopicmodelling.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
